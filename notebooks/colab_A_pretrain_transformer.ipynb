{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohit1053/quant-lab/blob/master/notebooks/colab_A_pretrain_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jSNadDMBGwL"
      },
      "source": [
        "# Notebook A: Pre-training + Transformer Training\n",
        "**Run on Colab Pro+ H100** | Part 1 of 3 parallel sessions\n",
        "- Pre-trains masked time-series encoder (BERT-like)\n",
        "- Trains Transformer forecaster with multi-task heads"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Mohit1053/quant-lab.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4DqYItwSmPs",
        "outputId": "82273a84-4189-458c-ecab-ad4386bfa58f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'quant-lab'...\n",
            "remote: Enumerating objects: 365, done.\u001b[K\n",
            "remote: Counting objects: 100% (365/365), done.\u001b[K\n",
            "remote: Compressing objects: 100% (218/218), done.\u001b[K\n",
            "remote: Total 365 (delta 134), reused 357 (delta 130), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (365/365), 197.42 KiB | 28.20 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "guJfT3WKBGwi",
        "outputId": "d2f8133e-70a6-4dad-b55c-1ee8d1e7e909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§¹ Removing existing quant-lab directory...\n",
            "ðŸ“¥ Cloning repository...\n",
            "âœ… Clone successful.\n",
            "ðŸ“¦ Installing package...\n",
            "âœ… Installation complete.\n",
            "ðŸ’¾ Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ðŸ“ Creating Drive directories...\n",
            "âœ… Drive directories ready.\n",
            "ðŸ–¥ï¸ Checking GPU...\n",
            "ðŸš€ GPU: NVIDIA H100 80GB HBM3\n",
            "ðŸ’¾ Memory: 85.0 GB\n",
            "ðŸ§  BF16 Support: True\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# ðŸš€ QUANT LAB â€“ COLAB SETUP\n",
        "# ==============================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_URL = \"https://github.com/Mohit1053/quant-lab.git\"\n",
        "CLONE_DIR = \"/content/quant-lab\"\n",
        "DRIVE_DIR = Path(\"/content/drive/MyDrive/quant_lab\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 1ï¸âƒ£ Reset Working Directory (prevents getcwd bug)\n",
        "# -------------------------------------------------\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 2ï¸âƒ£ Clean Broken / Partial Repo (safe re-run)\n",
        "# -------------------------------------------------\n",
        "if os.path.exists(CLONE_DIR):\n",
        "    print(\"ðŸ§¹ Removing existing quant-lab directory...\")\n",
        "    subprocess.run([\"rm\", \"-rf\", CLONE_DIR])\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3ï¸âƒ£ Clone Repository\n",
        "# -------------------------------------------------\n",
        "print(\"ðŸ“¥ Cloning repository...\")\n",
        "result = subprocess.run(\n",
        "    [\"git\", \"clone\", REPO_URL, CLONE_DIR],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(\"âŒ Git Clone Failed:\\n\")\n",
        "    print(result.stderr)\n",
        "    raise RuntimeError(\"Repository clone failed.\")\n",
        "\n",
        "print(\"âœ… Clone successful.\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 4ï¸âƒ£ Change into Repo Directory\n",
        "# -------------------------------------------------\n",
        "os.chdir(CLONE_DIR)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 5ï¸âƒ£ Install Package (editable mode)\n",
        "# -------------------------------------------------\n",
        "print(\"ðŸ“¦ Installing package...\")\n",
        "subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-e\", \".\"],\n",
        "    check=True\n",
        ")\n",
        "print(\"âœ… Installation complete.\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 6ï¸âƒ£ Mount Google Drive\n",
        "# -------------------------------------------------\n",
        "print(\"ðŸ’¾ Mounting Google Drive...\")\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 7ï¸âƒ£ Create Persistent Directory Structure\n",
        "# -------------------------------------------------\n",
        "print(\"ðŸ“ Creating Drive directories...\")\n",
        "for d in [\n",
        "    \"data/raw\",\n",
        "    \"data/cleaned\",\n",
        "    \"data/features\",\n",
        "    \"outputs/models/pretrained\",\n",
        "    \"outputs/models/transformer\",\n",
        "    \"outputs/mlruns\",\n",
        "]:\n",
        "    (DRIVE_DIR / d).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"âœ… Drive directories ready.\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 8ï¸âƒ£ GPU Information\n",
        "# -------------------------------------------------\n",
        "print(\"ðŸ–¥ï¸ Checking GPU...\")\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu = torch.cuda.get_device_name(0)\n",
        "    mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    bf16 = torch.cuda.is_bf16_supported()\n",
        "    print(f\"ðŸš€ GPU: {gpu}\")\n",
        "    print(f\"ðŸ’¾ Memory: {mem:.1f} GB\")\n",
        "    print(f\"ðŸ§  BF16 Support: {bf16}\")\n",
        "else:\n",
        "    print(\"âš ï¸ WARNING: No GPU detected.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip uninstall -y numpy pandas scipy scikit-learn\n",
        "!pip install --no-cache-dir numpy==1.26.4 pandas==2.2.2 scipy==1.11.4 scikit-learn==1.4.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4JPkChkwTdR1",
        "outputId": "add5c521-6f0c-4c2e-aeea-f427b599cf12"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Found existing installation: scipy 1.16.3\n",
            "Uninstalling scipy-1.16.3:\n",
            "  Successfully uninstalled scipy-1.16.3\n",
            "Found existing installation: scikit-learn 1.6.1\n",
            "Uninstalling scikit-learn-1.6.1:\n",
            "  Successfully uninstalled scikit-learn-1.6.1\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.2.2\n",
            "  Downloading pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting scipy==1.11.4\n",
            "  Downloading scipy-1.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m461.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.4.2\n",
            "  Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m460.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m220.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.8/35.8 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, pandas, scikit-learn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "libpysal 4.14.1 requires scipy>=1.12.0, but you have scipy 1.11.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "inequality 1.1.2 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "access 1.1.10.post3 requires scipy>=1.14.1, but you have scipy 1.11.4 which is incompatible.\n",
            "esda 2.8.1 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "mapclassify 2.10.0 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "spopt 0.7.0 requires scipy>=1.12.0, but you have scipy 1.11.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.11 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "giddy 2.3.8 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 pandas-2.2.2 scikit-learn-1.4.2 scipy-1.11.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "c3335b402afb4779ad2b81f48c5ef5b6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6eqr2HhcBGwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce41ef80-c013-4d80-9f0b-554aec498013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cached features from Drive...\n",
            "Features: 177187 rows, 49 tickers, 15 features\n"
          ]
        }
      ],
      "source": [
        "# === DATA PIPELINE ===\n",
        "# Check if Drive has cached data, otherwise download fresh\n",
        "import shutil\n",
        "\n",
        "drive_features = DRIVE_DIR / 'data/features/nifty50_features.parquet'\n",
        "local_features = Path('data/features/nifty50_features.parquet')\n",
        "\n",
        "if drive_features.exists():\n",
        "    print(\"Loading cached features from Drive...\")\n",
        "    Path('data/features').mkdir(parents=True, exist_ok=True)\n",
        "    shutil.copy(drive_features, local_features)\n",
        "    # Also copy cleaned data\n",
        "    if (DRIVE_DIR / 'data/cleaned/nifty50_cleaned.parquet').exists():\n",
        "        Path('data/cleaned').mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy(DRIVE_DIR / 'data/cleaned/nifty50_cleaned.parquet', 'data/cleaned/nifty50_cleaned.parquet')\n",
        "else:\n",
        "    print(\"Downloading fresh data from yfinance...\")\n",
        "    subprocess.run([sys.executable, 'scripts/ingest_data.py'], check=True)\n",
        "    subprocess.run([sys.executable, 'scripts/compute_features.py'], check=True)\n",
        "\n",
        "    # Cache to Drive\n",
        "    for src in ['data/raw', 'data/cleaned', 'data/features']:\n",
        "        src_p = Path(src)\n",
        "        if src_p.exists():\n",
        "            dst_p = DRIVE_DIR / src\n",
        "            dst_p.mkdir(parents=True, exist_ok=True)\n",
        "            for f in src_p.glob('*.parquet'):\n",
        "                shutil.copy(f, dst_p / f.name)\n",
        "    print(\"Data cached to Drive for other notebooks!\")\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_parquet(local_features)\n",
        "print(f\"Features: {df.shape[0]} rows, {df['ticker'].nunique()} tickers, {len([c for c in df.columns if c not in {'date','ticker','open','high','low','close','volume','adj_close'}])} features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNFhA3rpBGwo"
      },
      "source": [
        "## Pre-training: Masked Time-Series Encoder\n",
        "BERT-like pre-training with patch tokenization and 15% masking\n",
        "- H100 config: d_model=256, 6 layers, 100 epochs, batch_size=128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r5omVBV8BGwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "700176a2-4420-4f12-ba99-0aa3a6da6f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-19 09:50:28 [info     ] using_gpu                      memory_gb=79.2 name='NVIDIA H100 80GB HBM3'\n",
            "2026-02-19 09:50:28 [info     ] parquet_loaded                 cols=23 path=data/features/nifty50_features.parquet rows=177187\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3120 valid_samples=2869\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3332 valid_samples=3081\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=1388 valid_samples=1137\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:28 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=1420 valid_samples=1169\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=3331 valid_samples=3080\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=0 valid_samples=0\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 09:50:29 [info     ] split_train                    num_tickers=49 total_samples=146856\n",
            "2026-02-19 09:50:29 [info     ] split_val                      num_tickers=0 total_samples=0\n",
            "2026-02-19 09:50:29 [info     ] split_test                     num_tickers=49 total_samples=14945\n",
            "2026-02-19 09:50:29 [info     ] datamodule_setup               num_features=15 sequence_length=63 test_samples=14945 train_samples=146856 val_samples=0\n",
            "Encoder parameters: 5,165,387\n",
            "2026-02-19 09:50:33 [info     ] pretrain_start                 epochs=100 mask_ratio=0.15 parameters=5165387\n",
            "2026-02-19 09:50:46 [info     ] pretrain_epoch                 epoch=1 train_loss=0.422692 val_loss=N/A\n",
            "2026-02-19 09:50:58 [info     ] pretrain_epoch                 epoch=2 train_loss=0.174654 val_loss=N/A\n",
            "2026-02-19 09:51:10 [info     ] pretrain_epoch                 epoch=3 train_loss=0.130906 val_loss=N/A\n",
            "2026-02-19 09:51:22 [info     ] pretrain_epoch                 epoch=4 train_loss=0.117024 val_loss=N/A\n",
            "2026-02-19 09:51:34 [info     ] pretrain_epoch                 epoch=5 train_loss=0.106856 val_loss=N/A\n",
            "2026-02-19 09:51:46 [info     ] pretrain_epoch                 epoch=6 train_loss=0.099709 val_loss=N/A\n",
            "2026-02-19 09:51:58 [info     ] pretrain_epoch                 epoch=7 train_loss=0.095289 val_loss=N/A\n",
            "2026-02-19 09:52:10 [info     ] pretrain_epoch                 epoch=8 train_loss=0.091062 val_loss=N/A\n",
            "2026-02-19 09:52:23 [info     ] pretrain_epoch                 epoch=9 train_loss=0.087210 val_loss=N/A\n",
            "2026-02-19 09:52:35 [info     ] pretrain_epoch                 epoch=10 train_loss=0.083927 val_loss=N/A\n",
            "2026-02-19 09:52:47 [info     ] pretrain_epoch                 epoch=11 train_loss=0.081724 val_loss=N/A\n",
            "2026-02-19 09:53:00 [info     ] pretrain_epoch                 epoch=12 train_loss=0.079576 val_loss=N/A\n",
            "2026-02-19 09:53:12 [info     ] pretrain_epoch                 epoch=13 train_loss=0.078059 val_loss=N/A\n",
            "2026-02-19 09:53:25 [info     ] pretrain_epoch                 epoch=14 train_loss=0.075903 val_loss=N/A\n",
            "2026-02-19 09:53:37 [info     ] pretrain_epoch                 epoch=15 train_loss=0.074672 val_loss=N/A\n",
            "2026-02-19 09:53:50 [info     ] pretrain_epoch                 epoch=16 train_loss=0.073941 val_loss=N/A\n",
            "2026-02-19 09:54:03 [info     ] pretrain_epoch                 epoch=17 train_loss=0.071902 val_loss=N/A\n",
            "2026-02-19 09:54:15 [info     ] pretrain_epoch                 epoch=18 train_loss=0.070448 val_loss=N/A\n",
            "2026-02-19 09:54:28 [info     ] pretrain_epoch                 epoch=19 train_loss=0.069123 val_loss=N/A\n",
            "2026-02-19 09:54:40 [info     ] pretrain_epoch                 epoch=20 train_loss=0.069841 val_loss=N/A\n",
            "2026-02-19 09:54:53 [info     ] pretrain_epoch                 epoch=21 train_loss=0.068119 val_loss=N/A\n",
            "2026-02-19 09:55:05 [info     ] pretrain_epoch                 epoch=22 train_loss=0.067286 val_loss=N/A\n",
            "2026-02-19 09:55:18 [info     ] pretrain_epoch                 epoch=23 train_loss=0.065661 val_loss=N/A\n",
            "2026-02-19 09:55:31 [info     ] pretrain_epoch                 epoch=24 train_loss=0.065590 val_loss=N/A\n",
            "2026-02-19 09:55:43 [info     ] pretrain_epoch                 epoch=25 train_loss=0.064010 val_loss=N/A\n",
            "2026-02-19 09:55:56 [info     ] pretrain_epoch                 epoch=26 train_loss=0.063877 val_loss=N/A\n",
            "2026-02-19 09:56:08 [info     ] pretrain_epoch                 epoch=27 train_loss=0.064360 val_loss=N/A\n",
            "2026-02-19 09:56:21 [info     ] pretrain_epoch                 epoch=28 train_loss=0.062635 val_loss=N/A\n",
            "2026-02-19 09:56:34 [info     ] pretrain_epoch                 epoch=29 train_loss=0.062773 val_loss=N/A\n",
            "2026-02-19 09:56:47 [info     ] pretrain_epoch                 epoch=30 train_loss=0.062626 val_loss=N/A\n",
            "2026-02-19 09:57:00 [info     ] pretrain_epoch                 epoch=31 train_loss=0.062023 val_loss=N/A\n",
            "2026-02-19 09:57:12 [info     ] pretrain_epoch                 epoch=32 train_loss=0.061089 val_loss=N/A\n",
            "2026-02-19 09:57:25 [info     ] pretrain_epoch                 epoch=33 train_loss=0.060809 val_loss=N/A\n",
            "2026-02-19 09:57:37 [info     ] pretrain_epoch                 epoch=34 train_loss=0.060332 val_loss=N/A\n",
            "2026-02-19 09:57:50 [info     ] pretrain_epoch                 epoch=35 train_loss=0.059611 val_loss=N/A\n",
            "2026-02-19 09:58:02 [info     ] pretrain_epoch                 epoch=36 train_loss=0.058659 val_loss=N/A\n",
            "2026-02-19 09:58:14 [info     ] pretrain_epoch                 epoch=37 train_loss=0.058397 val_loss=N/A\n",
            "2026-02-19 09:58:27 [info     ] pretrain_epoch                 epoch=38 train_loss=0.058774 val_loss=N/A\n",
            "2026-02-19 09:58:39 [info     ] pretrain_epoch                 epoch=39 train_loss=0.058300 val_loss=N/A\n",
            "2026-02-19 09:58:52 [info     ] pretrain_epoch                 epoch=40 train_loss=0.057973 val_loss=N/A\n",
            "2026-02-19 09:59:04 [info     ] pretrain_epoch                 epoch=41 train_loss=0.058287 val_loss=N/A\n",
            "2026-02-19 09:59:17 [info     ] pretrain_epoch                 epoch=42 train_loss=0.057088 val_loss=N/A\n",
            "2026-02-19 09:59:30 [info     ] pretrain_epoch                 epoch=43 train_loss=0.057181 val_loss=N/A\n",
            "2026-02-19 09:59:42 [info     ] pretrain_epoch                 epoch=44 train_loss=0.056017 val_loss=N/A\n",
            "2026-02-19 09:59:55 [info     ] pretrain_epoch                 epoch=45 train_loss=0.056250 val_loss=N/A\n",
            "2026-02-19 10:00:08 [info     ] pretrain_epoch                 epoch=46 train_loss=0.056242 val_loss=N/A\n",
            "2026-02-19 10:00:20 [info     ] pretrain_epoch                 epoch=47 train_loss=0.055601 val_loss=N/A\n",
            "2026-02-19 10:00:33 [info     ] pretrain_epoch                 epoch=48 train_loss=0.055058 val_loss=N/A\n",
            "2026-02-19 10:00:45 [info     ] pretrain_epoch                 epoch=49 train_loss=0.055776 val_loss=N/A\n",
            "2026-02-19 10:00:58 [info     ] pretrain_epoch                 epoch=50 train_loss=0.054498 val_loss=N/A\n",
            "2026-02-19 10:01:10 [info     ] pretrain_epoch                 epoch=51 train_loss=0.055470 val_loss=N/A\n",
            "2026-02-19 10:01:23 [info     ] pretrain_epoch                 epoch=52 train_loss=0.054788 val_loss=N/A\n",
            "2026-02-19 10:01:35 [info     ] pretrain_epoch                 epoch=53 train_loss=0.054836 val_loss=N/A\n",
            "2026-02-19 10:01:48 [info     ] pretrain_epoch                 epoch=54 train_loss=0.054764 val_loss=N/A\n",
            "2026-02-19 10:02:01 [info     ] pretrain_epoch                 epoch=55 train_loss=0.053876 val_loss=N/A\n",
            "2026-02-19 10:02:13 [info     ] pretrain_epoch                 epoch=56 train_loss=0.053434 val_loss=N/A\n",
            "2026-02-19 10:02:26 [info     ] pretrain_epoch                 epoch=57 train_loss=0.053747 val_loss=N/A\n",
            "2026-02-19 10:02:38 [info     ] pretrain_epoch                 epoch=58 train_loss=0.053777 val_loss=N/A\n",
            "2026-02-19 10:02:51 [info     ] pretrain_epoch                 epoch=59 train_loss=0.052710 val_loss=N/A\n",
            "2026-02-19 10:03:03 [info     ] pretrain_epoch                 epoch=60 train_loss=0.052148 val_loss=N/A\n",
            "2026-02-19 10:03:16 [info     ] pretrain_epoch                 epoch=61 train_loss=0.052163 val_loss=N/A\n",
            "2026-02-19 10:03:29 [info     ] pretrain_epoch                 epoch=62 train_loss=0.052705 val_loss=N/A\n",
            "2026-02-19 10:03:41 [info     ] pretrain_epoch                 epoch=63 train_loss=0.052374 val_loss=N/A\n",
            "2026-02-19 10:03:53 [info     ] pretrain_epoch                 epoch=64 train_loss=0.052211 val_loss=N/A\n",
            "2026-02-19 10:04:06 [info     ] pretrain_epoch                 epoch=65 train_loss=0.052339 val_loss=N/A\n",
            "2026-02-19 10:04:19 [info     ] pretrain_epoch                 epoch=66 train_loss=0.052412 val_loss=N/A\n",
            "2026-02-19 10:04:31 [info     ] pretrain_epoch                 epoch=67 train_loss=0.052030 val_loss=N/A\n",
            "2026-02-19 10:04:44 [info     ] pretrain_epoch                 epoch=68 train_loss=0.052883 val_loss=N/A\n",
            "2026-02-19 10:04:56 [info     ] pretrain_epoch                 epoch=69 train_loss=0.051861 val_loss=N/A\n",
            "2026-02-19 10:05:09 [info     ] pretrain_epoch                 epoch=70 train_loss=0.051668 val_loss=N/A\n",
            "2026-02-19 10:05:21 [info     ] pretrain_epoch                 epoch=71 train_loss=0.050979 val_loss=N/A\n",
            "2026-02-19 10:05:34 [info     ] pretrain_epoch                 epoch=72 train_loss=0.051853 val_loss=N/A\n",
            "2026-02-19 10:05:46 [info     ] pretrain_epoch                 epoch=73 train_loss=0.050981 val_loss=N/A\n",
            "2026-02-19 10:05:58 [info     ] pretrain_epoch                 epoch=74 train_loss=0.051958 val_loss=N/A\n",
            "2026-02-19 10:06:11 [info     ] pretrain_epoch                 epoch=75 train_loss=0.051536 val_loss=N/A\n",
            "2026-02-19 10:06:23 [info     ] pretrain_epoch                 epoch=76 train_loss=0.051572 val_loss=N/A\n",
            "2026-02-19 10:06:36 [info     ] pretrain_epoch                 epoch=77 train_loss=0.050758 val_loss=N/A\n",
            "2026-02-19 10:06:48 [info     ] pretrain_epoch                 epoch=78 train_loss=0.051164 val_loss=N/A\n",
            "2026-02-19 10:07:01 [info     ] pretrain_epoch                 epoch=79 train_loss=0.051212 val_loss=N/A\n",
            "2026-02-19 10:07:13 [info     ] pretrain_epoch                 epoch=80 train_loss=0.050472 val_loss=N/A\n",
            "2026-02-19 10:07:26 [info     ] pretrain_epoch                 epoch=81 train_loss=0.051193 val_loss=N/A\n",
            "2026-02-19 10:07:38 [info     ] pretrain_epoch                 epoch=82 train_loss=0.050933 val_loss=N/A\n",
            "2026-02-19 10:07:50 [info     ] pretrain_epoch                 epoch=83 train_loss=0.050128 val_loss=N/A\n",
            "2026-02-19 10:08:03 [info     ] pretrain_epoch                 epoch=84 train_loss=0.049949 val_loss=N/A\n",
            "2026-02-19 10:08:15 [info     ] pretrain_epoch                 epoch=85 train_loss=0.050641 val_loss=N/A\n",
            "2026-02-19 10:08:28 [info     ] pretrain_epoch                 epoch=86 train_loss=0.049901 val_loss=N/A\n",
            "2026-02-19 10:08:40 [info     ] pretrain_epoch                 epoch=87 train_loss=0.050403 val_loss=N/A\n",
            "2026-02-19 10:08:53 [info     ] pretrain_epoch                 epoch=88 train_loss=0.050883 val_loss=N/A\n",
            "2026-02-19 10:09:05 [info     ] pretrain_epoch                 epoch=89 train_loss=0.049542 val_loss=N/A\n",
            "2026-02-19 10:09:18 [info     ] pretrain_epoch                 epoch=90 train_loss=0.050033 val_loss=N/A\n",
            "2026-02-19 10:09:30 [info     ] pretrain_epoch                 epoch=91 train_loss=0.049841 val_loss=N/A\n",
            "2026-02-19 10:09:42 [info     ] pretrain_epoch                 epoch=92 train_loss=0.050762 val_loss=N/A\n",
            "2026-02-19 10:09:55 [info     ] pretrain_epoch                 epoch=93 train_loss=0.050105 val_loss=N/A\n",
            "2026-02-19 10:10:07 [info     ] pretrain_epoch                 epoch=94 train_loss=0.049648 val_loss=N/A\n",
            "2026-02-19 10:10:19 [info     ] pretrain_epoch                 epoch=95 train_loss=0.050317 val_loss=N/A\n",
            "2026-02-19 10:10:32 [info     ] pretrain_epoch                 epoch=96 train_loss=0.049585 val_loss=N/A\n",
            "2026-02-19 10:10:44 [info     ] pretrain_epoch                 epoch=97 train_loss=0.050469 val_loss=N/A\n",
            "2026-02-19 10:10:57 [info     ] pretrain_epoch                 epoch=98 train_loss=0.049351 val_loss=N/A\n",
            "2026-02-19 10:11:09 [info     ] pretrain_epoch                 epoch=99 train_loss=0.050120 val_loss=N/A\n",
            "2026-02-19 10:11:22 [info     ] pretrain_epoch                 epoch=100 train_loss=0.050538 val_loss=N/A\n",
            "2026-02-19 10:11:22 [info     ] pretrain_complete              epochs_run=100\n",
            "\n",
            "Pre-training done in 20.8 min | Final loss: 0.050538\n",
            "Embeddings shape: (146816, 256)\n",
            "Pre-trained model saved to Drive!\n"
          ]
        }
      ],
      "source": [
        "# === PRE-TRAINING (H100 optimized) ===\n",
        "import time\n",
        "from quant_lab.utils.seed import set_global_seed\n",
        "from quant_lab.utils.device import get_device\n",
        "from quant_lab.data.datasets import TemporalSplit\n",
        "from quant_lab.data.datamodule import QuantDataModule, DataModuleConfig\n",
        "from quant_lab.data.storage.parquet_store import ParquetStore\n",
        "from quant_lab.features.engine import FeatureEngine\n",
        "from quant_lab.representation.masked_encoder import MaskedTimeSeriesEncoder, MaskedEncoderConfig\n",
        "from quant_lab.representation.pretraining import PreTrainer, PretrainConfig\n",
        "from quant_lab.representation.embedding_space import EmbeddingExtractor\n",
        "\n",
        "set_global_seed(42)\n",
        "device = get_device()\n",
        "\n",
        "# Load features\n",
        "store = ParquetStore(base_dir='data/features')\n",
        "feature_df = store.load('nifty50_features')\n",
        "\n",
        "engine = FeatureEngine(\n",
        "    enabled_features=['log_returns', 'realized_volatility', 'momentum', 'max_drawdown'],\n",
        "    windows={'short': [1, 5], 'medium': [21], 'long': [63]},\n",
        ")\n",
        "feature_cols = engine.get_feature_columns(feature_df)\n",
        "\n",
        "# Use train+val for pre-training (more data)\n",
        "split = TemporalSplit(train_end='2023-06-30', val_end='2023-06-30')\n",
        "dm = QuantDataModule(\n",
        "    feature_df, feature_cols, split,\n",
        "    DataModuleConfig(sequence_length=63, batch_size=128, num_workers=2),\n",
        ")\n",
        "dm.setup()\n",
        "train_loader = dm.train_dataloader()\n",
        "\n",
        "# H100-optimized: larger model\n",
        "encoder_config = MaskedEncoderConfig(\n",
        "    num_features=dm.num_features,\n",
        "    patch_size=5,\n",
        "    d_model=256,\n",
        "    nhead=8,\n",
        "    num_encoder_layers=6,\n",
        "    dim_feedforward=1024,\n",
        "    dropout=0.1,\n",
        "    mask_ratio=0.15,\n",
        ")\n",
        "model = MaskedTimeSeriesEncoder(encoder_config)\n",
        "print(f\"Encoder parameters: {model.count_parameters():,}\")\n",
        "\n",
        "# Pre-train\n",
        "pt_config = PretrainConfig(\n",
        "    epochs=100,\n",
        "    learning_rate=1e-4,\n",
        "    mask_ratio=0.15,\n",
        "    mixed_precision=True,\n",
        "    checkpoint_dir='outputs/models/pretrained',\n",
        ")\n",
        "pretrainer = PreTrainer(model, pt_config, device)\n",
        "\n",
        "start = time.time()\n",
        "history = pretrainer.fit(train_loader)\n",
        "elapsed = time.time() - start\n",
        "print(f\"\\nPre-training done in {elapsed/60:.1f} min | Final loss: {history['train_loss'][-1]:.6f}\")\n",
        "\n",
        "# Save model\n",
        "model.save(Path('outputs/models/pretrained/masked_encoder.pt'))\n",
        "\n",
        "# Extract embeddings\n",
        "extractor = EmbeddingExtractor(model, device)\n",
        "embeddings = extractor.extract(train_loader)\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "\n",
        "# Save to Drive\n",
        "import shutil\n",
        "for f in Path('outputs/models/pretrained').glob('*'):\n",
        "    shutil.copy(f, DRIVE_DIR / 'outputs/models/pretrained' / f.name)\n",
        "print(\"Pre-trained model saved to Drive!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-m-YiRsBGwq"
      },
      "source": [
        "## Transformer Forecaster Training\n",
        "Multi-task heads: return distribution (Gaussian) + direction (3-class) + volatility\n",
        "- H100 config: d_model=256, 6 layers, 100 epochs, batch_size=128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8tpHkPVyBGwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a48a15c-c64a-4251-9fe8-55c01fde13f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-19 10:11:25 [info     ] using_gpu                      memory_gb=79.2 name='NVIDIA H100 80GB HBM3'\n",
            "2026-02-19 10:11:25 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:25 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:25 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:25 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:25 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:25 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:25 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2750 valid_samples=2499\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2962 valid_samples=2711\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=1018 valid_samples=767\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=1050 valid_samples=799\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=2961 valid_samples=2710\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=370 valid_samples=307\n",
            "2026-02-19 10:11:26 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [debug    ] dataset_created                num_features=15 sequence_length=63 total_rows=368 valid_samples=305\n",
            "2026-02-19 10:11:27 [info     ] split_train                    num_tickers=49 total_samples=128726\n",
            "2026-02-19 10:11:27 [info     ] split_val                      num_tickers=49 total_samples=15043\n",
            "2026-02-19 10:11:27 [info     ] split_test                     num_tickers=49 total_samples=14945\n",
            "2026-02-19 10:11:27 [info     ] datamodule_setup               num_features=15 sequence_length=63 test_samples=14945 train_samples=128726 val_samples=15043\n",
            "Transformer parameters: 4,744,966\n",
            "2026-02-19 10:11:27 [info     ] training_start                 amp_dtype=torch.bfloat16 device=cuda epochs=100 parameters=4744966 total_steps=100500\n",
            "2026-02-19 10:11:28 [debug    ] train_step                     loss=-0.414051 lr=5.00e-06 step=50\n",
            "2026-02-19 10:11:28 [debug    ] train_step                     loss=-0.911626 lr=1.00e-05 step=100\n",
            "2026-02-19 10:11:29 [debug    ] train_step                     loss=-1.126983 lr=1.50e-05 step=150\n",
            "2026-02-19 10:11:29 [debug    ] train_step                     loss=-1.514916 lr=2.00e-05 step=200\n",
            "2026-02-19 10:11:30 [debug    ] train_step                     loss=-1.621507 lr=2.50e-05 step=250\n",
            "2026-02-19 10:11:30 [debug    ] train_step                     loss=-1.610071 lr=3.00e-05 step=300\n",
            "2026-02-19 10:11:31 [debug    ] train_step                     loss=-1.397611 lr=3.50e-05 step=350\n",
            "2026-02-19 10:11:31 [debug    ] train_step                     loss=-1.958365 lr=4.00e-05 step=400\n",
            "2026-02-19 10:11:32 [debug    ] train_step                     loss=-1.527382 lr=4.50e-05 step=450\n",
            "2026-02-19 10:11:32 [debug    ] train_step                     loss=-2.152045 lr=5.00e-05 step=500\n",
            "2026-02-19 10:11:33 [debug    ] train_step                     loss=-1.538272 lr=5.50e-05 step=550\n",
            "2026-02-19 10:11:33 [debug    ] train_step                     loss=-2.140841 lr=6.00e-05 step=600\n",
            "2026-02-19 10:11:34 [debug    ] train_step                     loss=-1.688078 lr=6.50e-05 step=650\n",
            "2026-02-19 10:11:34 [debug    ] train_step                     loss=-2.160171 lr=7.00e-05 step=700\n",
            "2026-02-19 10:11:35 [debug    ] train_step                     loss=-1.852707 lr=7.50e-05 step=750\n",
            "2026-02-19 10:11:35 [debug    ] train_step                     loss=-2.273989 lr=8.00e-05 step=800\n",
            "2026-02-19 10:11:36 [debug    ] train_step                     loss=-1.693966 lr=8.50e-05 step=850\n",
            "2026-02-19 10:11:36 [debug    ] train_step                     loss=-2.274064 lr=9.00e-05 step=900\n",
            "2026-02-19 10:11:37 [debug    ] train_step                     loss=-1.753839 lr=9.50e-05 step=950\n",
            "2026-02-19 10:11:38 [debug    ] train_step                     loss=-2.346105 lr=1.00e-04 step=1000\n",
            "2026-02-19 10:11:38 [info     ] epoch_complete                 epoch=1 lr=1.00e-04 train_loss=-1.659609 val_loss=-1.952192\n",
            "2026-02-19 10:11:38 [info     ] checkpoint_saved               epoch=0 path=best.pt score=-1.9521915963140584\n",
            "2026-02-19 10:11:39 [debug    ] train_step                     loss=-1.720580 lr=1.00e-04 step=1050\n",
            "2026-02-19 10:11:39 [debug    ] train_step                     loss=-2.357539 lr=1.00e-04 step=1100\n",
            "2026-02-19 10:11:40 [debug    ] train_step                     loss=-1.972451 lr=1.00e-04 step=1150\n",
            "2026-02-19 10:11:40 [debug    ] train_step                     loss=-2.458852 lr=1.00e-04 step=1200\n",
            "2026-02-19 10:11:41 [debug    ] train_step                     loss=-1.828646 lr=1.00e-04 step=1250\n",
            "2026-02-19 10:11:41 [debug    ] train_step                     loss=-2.542353 lr=1.00e-04 step=1300\n",
            "2026-02-19 10:11:42 [debug    ] train_step                     loss=-1.764109 lr=1.00e-04 step=1350\n",
            "2026-02-19 10:11:42 [debug    ] train_step                     loss=-2.366980 lr=1.00e-04 step=1400\n",
            "2026-02-19 10:11:43 [debug    ] train_step                     loss=-2.107677 lr=1.00e-04 step=1450\n",
            "2026-02-19 10:11:44 [debug    ] train_step                     loss=-2.429319 lr=1.00e-04 step=1500\n",
            "2026-02-19 10:11:44 [debug    ] train_step                     loss=-2.054544 lr=1.00e-04 step=1550\n",
            "2026-02-19 10:11:45 [debug    ] train_step                     loss=-2.701742 lr=1.00e-04 step=1600\n",
            "2026-02-19 10:11:45 [debug    ] train_step                     loss=-2.221504 lr=1.00e-04 step=1650\n",
            "2026-02-19 10:11:46 [debug    ] train_step                     loss=-2.628806 lr=1.00e-04 step=1700\n",
            "2026-02-19 10:11:46 [debug    ] train_step                     loss=-2.286927 lr=1.00e-04 step=1750\n",
            "2026-02-19 10:11:47 [debug    ] train_step                     loss=-2.704001 lr=1.00e-04 step=1800\n",
            "2026-02-19 10:11:47 [debug    ] train_step                     loss=-2.366946 lr=1.00e-04 step=1850\n",
            "2026-02-19 10:11:48 [debug    ] train_step                     loss=-2.663017 lr=1.00e-04 step=1900\n",
            "2026-02-19 10:11:48 [debug    ] train_step                     loss=-2.425125 lr=1.00e-04 step=1950\n",
            "2026-02-19 10:11:49 [debug    ] train_step                     loss=-2.668526 lr=1.00e-04 step=2000\n",
            "2026-02-19 10:11:49 [info     ] epoch_complete                 epoch=2 lr=1.00e-04 train_loss=-2.301789 val_loss=-2.531359\n",
            "2026-02-19 10:11:50 [info     ] checkpoint_saved               epoch=1 path=best.pt score=-2.531358505709697\n",
            "2026-02-19 10:11:50 [debug    ] train_step                     loss=-2.264847 lr=1.00e-04 step=2050\n",
            "2026-02-19 10:11:51 [debug    ] train_step                     loss=-2.585978 lr=1.00e-04 step=2100\n",
            "2026-02-19 10:11:51 [debug    ] train_step                     loss=-2.449393 lr=1.00e-04 step=2150\n",
            "2026-02-19 10:11:52 [debug    ] train_step                     loss=-2.788309 lr=1.00e-04 step=2200\n",
            "2026-02-19 10:11:52 [debug    ] train_step                     loss=-2.108030 lr=1.00e-04 step=2250\n",
            "2026-02-19 10:11:53 [debug    ] train_step                     loss=-2.571276 lr=1.00e-04 step=2300\n",
            "2026-02-19 10:11:53 [debug    ] train_step                     loss=-2.634668 lr=1.00e-04 step=2350\n",
            "2026-02-19 10:11:54 [debug    ] train_step                     loss=-2.041850 lr=1.00e-04 step=2400\n",
            "2026-02-19 10:11:54 [debug    ] train_step                     loss=-2.848363 lr=9.99e-05 step=2450\n",
            "2026-02-19 10:11:55 [debug    ] train_step                     loss=-2.821243 lr=9.99e-05 step=2500\n",
            "2026-02-19 10:11:55 [debug    ] train_step                     loss=-1.825786 lr=9.99e-05 step=2550\n",
            "2026-02-19 10:11:56 [debug    ] train_step                     loss=-2.461038 lr=9.99e-05 step=2600\n",
            "2026-02-19 10:11:56 [debug    ] train_step                     loss=-2.710476 lr=9.99e-05 step=2650\n",
            "2026-02-19 10:11:57 [debug    ] train_step                     loss=-2.718019 lr=9.99e-05 step=2700\n",
            "2026-02-19 10:11:57 [debug    ] train_step                     loss=-2.879064 lr=9.99e-05 step=2750\n",
            "2026-02-19 10:11:58 [debug    ] train_step                     loss=-2.872542 lr=9.99e-05 step=2800\n",
            "2026-02-19 10:11:58 [debug    ] train_step                     loss=-2.930310 lr=9.99e-05 step=2850\n",
            "2026-02-19 10:11:59 [debug    ] train_step                     loss=-2.985821 lr=9.99e-05 step=2900\n",
            "2026-02-19 10:12:00 [debug    ] train_step                     loss=-3.024009 lr=9.99e-05 step=2950\n",
            "2026-02-19 10:12:00 [debug    ] train_step                     loss=-2.947619 lr=9.99e-05 step=3000\n",
            "2026-02-19 10:12:01 [info     ] epoch_complete                 epoch=3 lr=9.99e-05 train_loss=-2.577811 val_loss=-2.917338\n",
            "2026-02-19 10:12:01 [info     ] checkpoint_saved               epoch=2 path=best.pt score=-2.917338345010402\n",
            "2026-02-19 10:12:01 [debug    ] train_step                     loss=-2.614305 lr=9.99e-05 step=3050\n",
            "2026-02-19 10:12:02 [debug    ] train_step                     loss=-2.966573 lr=9.99e-05 step=3100\n",
            "2026-02-19 10:12:02 [debug    ] train_step                     loss=-2.653280 lr=9.99e-05 step=3150\n",
            "2026-02-19 10:12:03 [debug    ] train_step                     loss=-2.974096 lr=9.99e-05 step=3200\n",
            "2026-02-19 10:12:03 [debug    ] train_step                     loss=-2.992637 lr=9.99e-05 step=3250\n",
            "2026-02-19 10:12:04 [debug    ] train_step                     loss=-2.541676 lr=9.99e-05 step=3300\n",
            "2026-02-19 10:12:04 [debug    ] train_step                     loss=-2.895720 lr=9.99e-05 step=3350\n",
            "2026-02-19 10:12:05 [debug    ] train_step                     loss=-2.885406 lr=9.99e-05 step=3400\n",
            "2026-02-19 10:12:05 [debug    ] train_step                     loss=-2.986520 lr=9.99e-05 step=3450\n",
            "2026-02-19 10:12:06 [debug    ] train_step                     loss=-2.657568 lr=9.98e-05 step=3500\n",
            "2026-02-19 10:12:06 [debug    ] train_step                     loss=-2.357952 lr=9.98e-05 step=3550\n",
            "2026-02-19 10:12:07 [debug    ] train_step                     loss=-2.903988 lr=9.98e-05 step=3600\n",
            "2026-02-19 10:12:08 [debug    ] train_step                     loss=-2.906293 lr=9.98e-05 step=3650\n",
            "2026-02-19 10:12:08 [debug    ] train_step                     loss=-2.934474 lr=9.98e-05 step=3700\n",
            "2026-02-19 10:12:09 [debug    ] train_step                     loss=-2.938210 lr=9.98e-05 step=3750\n",
            "2026-02-19 10:12:09 [debug    ] train_step                     loss=-3.037659 lr=9.98e-05 step=3800\n",
            "2026-02-19 10:12:10 [debug    ] train_step                     loss=-3.078085 lr=9.98e-05 step=3850\n",
            "2026-02-19 10:12:10 [debug    ] train_step                     loss=-2.987296 lr=9.98e-05 step=3900\n",
            "2026-02-19 10:12:11 [debug    ] train_step                     loss=-2.938270 lr=9.98e-05 step=3950\n",
            "2026-02-19 10:12:11 [debug    ] train_step                     loss=-3.010803 lr=9.98e-05 step=4000\n",
            "2026-02-19 10:12:12 [info     ] epoch_complete                 epoch=4 lr=9.98e-05 train_loss=-2.802632 val_loss=-3.247800\n",
            "2026-02-19 10:12:12 [info     ] checkpoint_saved               epoch=3 path=best.pt score=-3.247800335035486\n",
            "2026-02-19 10:12:12 [debug    ] train_step                     loss=-2.858764 lr=9.98e-05 step=4050\n",
            "2026-02-19 10:12:13 [debug    ] train_step                     loss=-3.092200 lr=9.98e-05 step=4100\n",
            "2026-02-19 10:12:14 [debug    ] train_step                     loss=-3.153349 lr=9.98e-05 step=4150\n",
            "2026-02-19 10:12:14 [debug    ] train_step                     loss=-2.921463 lr=9.97e-05 step=4200\n",
            "2026-02-19 10:12:15 [debug    ] train_step                     loss=-2.790056 lr=9.97e-05 step=4250\n",
            "2026-02-19 10:12:15 [debug    ] train_step                     loss=-3.099745 lr=9.97e-05 step=4300\n",
            "2026-02-19 10:12:16 [debug    ] train_step                     loss=-3.103435 lr=9.97e-05 step=4350\n",
            "2026-02-19 10:12:16 [debug    ] train_step                     loss=-2.852034 lr=9.97e-05 step=4400\n",
            "2026-02-19 10:12:17 [debug    ] train_step                     loss=-2.887273 lr=9.97e-05 step=4450\n",
            "2026-02-19 10:12:17 [debug    ] train_step                     loss=-2.791242 lr=9.97e-05 step=4500\n",
            "2026-02-19 10:12:18 [debug    ] train_step                     loss=-3.004962 lr=9.97e-05 step=4550\n",
            "2026-02-19 10:12:18 [debug    ] train_step                     loss=-2.758419 lr=9.97e-05 step=4600\n",
            "2026-02-19 10:12:19 [debug    ] train_step                     loss=-3.008684 lr=9.97e-05 step=4650\n",
            "2026-02-19 10:12:19 [debug    ] train_step                     loss=-2.460810 lr=9.97e-05 step=4700\n",
            "2026-02-19 10:12:20 [debug    ] train_step                     loss=-3.081296 lr=9.97e-05 step=4750\n",
            "2026-02-19 10:12:20 [debug    ] train_step                     loss=-2.930973 lr=9.96e-05 step=4800\n",
            "2026-02-19 10:12:21 [debug    ] train_step                     loss=-2.963219 lr=9.96e-05 step=4850\n",
            "2026-02-19 10:12:21 [debug    ] train_step                     loss=-3.088015 lr=9.96e-05 step=4900\n",
            "2026-02-19 10:12:22 [debug    ] train_step                     loss=-2.946757 lr=9.96e-05 step=4950\n",
            "2026-02-19 10:12:22 [debug    ] train_step                     loss=-2.741796 lr=9.96e-05 step=5000\n",
            "2026-02-19 10:12:23 [info     ] epoch_complete                 epoch=5 lr=9.96e-05 train_loss=-2.937712 val_loss=-3.256475\n",
            "2026-02-19 10:12:23 [info     ] checkpoint_saved               epoch=4 path=best.pt score=-3.2564754587108804\n",
            "2026-02-19 10:12:24 [debug    ] train_step                     loss=-2.851022 lr=9.96e-05 step=5050\n",
            "2026-02-19 10:12:24 [debug    ] train_step                     loss=-2.955651 lr=9.96e-05 step=5100\n",
            "2026-02-19 10:12:25 [debug    ] train_step                     loss=-2.808816 lr=9.96e-05 step=5150\n",
            "2026-02-19 10:12:25 [debug    ] train_step                     loss=-2.966094 lr=9.96e-05 step=5200\n",
            "2026-02-19 10:12:26 [debug    ] train_step                     loss=-2.826411 lr=9.96e-05 step=5250\n",
            "2026-02-19 10:12:26 [debug    ] train_step                     loss=-2.983830 lr=9.95e-05 step=5300\n",
            "2026-02-19 10:12:27 [debug    ] train_step                     loss=-3.145947 lr=9.95e-05 step=5350\n",
            "2026-02-19 10:12:27 [debug    ] train_step                     loss=-3.164752 lr=9.95e-05 step=5400\n",
            "2026-02-19 10:12:28 [debug    ] train_step                     loss=-3.150208 lr=9.95e-05 step=5450\n",
            "2026-02-19 10:12:28 [debug    ] train_step                     loss=-2.749840 lr=9.95e-05 step=5500\n",
            "2026-02-19 10:12:29 [debug    ] train_step                     loss=-2.793330 lr=9.95e-05 step=5550\n",
            "2026-02-19 10:12:29 [debug    ] train_step                     loss=-3.097771 lr=9.95e-05 step=5600\n",
            "2026-02-19 10:12:30 [debug    ] train_step                     loss=-2.765372 lr=9.95e-05 step=5650\n",
            "2026-02-19 10:12:30 [debug    ] train_step                     loss=-3.110186 lr=9.95e-05 step=5700\n",
            "2026-02-19 10:12:31 [debug    ] train_step                     loss=-3.142093 lr=9.94e-05 step=5750\n",
            "2026-02-19 10:12:31 [debug    ] train_step                     loss=-2.796932 lr=9.94e-05 step=5800\n",
            "2026-02-19 10:12:32 [debug    ] train_step                     loss=-3.072579 lr=9.94e-05 step=5850\n",
            "2026-02-19 10:12:32 [debug    ] train_step                     loss=-2.903311 lr=9.94e-05 step=5900\n",
            "2026-02-19 10:12:33 [debug    ] train_step                     loss=-3.229590 lr=9.94e-05 step=5950\n",
            "2026-02-19 10:12:33 [debug    ] train_step                     loss=-2.894570 lr=9.94e-05 step=6000\n",
            "2026-02-19 10:12:34 [info     ] epoch_complete                 epoch=6 lr=9.94e-05 train_loss=-2.932762 val_loss=-3.141081\n",
            "2026-02-19 10:12:35 [debug    ] train_step                     loss=-3.177707 lr=9.94e-05 step=6050\n",
            "2026-02-19 10:12:35 [debug    ] train_step                     loss=-3.148262 lr=9.94e-05 step=6100\n",
            "2026-02-19 10:12:36 [debug    ] train_step                     loss=-3.213821 lr=9.93e-05 step=6150\n",
            "2026-02-19 10:12:36 [debug    ] train_step                     loss=-2.749621 lr=9.93e-05 step=6200\n",
            "2026-02-19 10:12:37 [debug    ] train_step                     loss=-2.784157 lr=9.93e-05 step=6250\n",
            "2026-02-19 10:12:37 [debug    ] train_step                     loss=-3.109703 lr=9.93e-05 step=6300\n",
            "2026-02-19 10:12:38 [debug    ] train_step                     loss=-3.049661 lr=9.93e-05 step=6350\n",
            "2026-02-19 10:12:38 [debug    ] train_step                     loss=-2.610577 lr=9.93e-05 step=6400\n",
            "2026-02-19 10:12:39 [debug    ] train_step                     loss=-3.082641 lr=9.93e-05 step=6450\n",
            "2026-02-19 10:12:39 [debug    ] train_step                     loss=-2.694585 lr=9.93e-05 step=6500\n",
            "2026-02-19 10:12:40 [debug    ] train_step                     loss=-2.988264 lr=9.92e-05 step=6550\n",
            "2026-02-19 10:12:40 [debug    ] train_step                     loss=-3.073006 lr=9.92e-05 step=6600\n",
            "2026-02-19 10:12:41 [debug    ] train_step                     loss=-3.045134 lr=9.92e-05 step=6650\n",
            "2026-02-19 10:12:41 [debug    ] train_step                     loss=-2.994168 lr=9.92e-05 step=6700\n",
            "2026-02-19 10:12:42 [debug    ] train_step                     loss=-2.893430 lr=9.92e-05 step=6750\n",
            "2026-02-19 10:12:42 [debug    ] train_step                     loss=-2.762469 lr=9.92e-05 step=6800\n",
            "2026-02-19 10:12:43 [debug    ] train_step                     loss=-3.004652 lr=9.92e-05 step=6850\n",
            "2026-02-19 10:12:43 [debug    ] train_step                     loss=-3.032066 lr=9.91e-05 step=6900\n",
            "2026-02-19 10:12:44 [debug    ] train_step                     loss=-3.170112 lr=9.91e-05 step=6950\n",
            "2026-02-19 10:12:45 [debug    ] train_step                     loss=-3.171991 lr=9.91e-05 step=7000\n",
            "2026-02-19 10:12:45 [info     ] epoch_complete                 epoch=7 lr=9.91e-05 train_loss=-2.987341 val_loss=-3.252482\n",
            "2026-02-19 10:12:46 [debug    ] train_step                     loss=-3.062418 lr=9.91e-05 step=7050\n",
            "2026-02-19 10:12:46 [debug    ] train_step                     loss=-3.113778 lr=9.91e-05 step=7100\n",
            "2026-02-19 10:12:47 [debug    ] train_step                     loss=-2.987543 lr=9.91e-05 step=7150\n",
            "2026-02-19 10:12:47 [debug    ] train_step                     loss=-3.114885 lr=9.91e-05 step=7200\n",
            "2026-02-19 10:12:48 [debug    ] train_step                     loss=-3.115091 lr=9.90e-05 step=7250\n",
            "2026-02-19 10:12:48 [debug    ] train_step                     loss=-3.168481 lr=9.90e-05 step=7300\n",
            "2026-02-19 10:12:49 [debug    ] train_step                     loss=-3.091669 lr=9.90e-05 step=7350\n",
            "2026-02-19 10:12:49 [debug    ] train_step                     loss=-3.076901 lr=9.90e-05 step=7400\n",
            "2026-02-19 10:12:50 [debug    ] train_step                     loss=-3.138194 lr=9.90e-05 step=7450\n",
            "2026-02-19 10:12:50 [debug    ] train_step                     loss=-2.726092 lr=9.90e-05 step=7500\n",
            "2026-02-19 10:12:51 [debug    ] train_step                     loss=-3.092916 lr=9.89e-05 step=7550\n",
            "2026-02-19 10:12:51 [debug    ] train_step                     loss=-3.141966 lr=9.89e-05 step=7600\n",
            "2026-02-19 10:12:52 [debug    ] train_step                     loss=-3.169698 lr=9.89e-05 step=7650\n",
            "2026-02-19 10:12:53 [debug    ] train_step                     loss=-3.028138 lr=9.89e-05 step=7700\n",
            "2026-02-19 10:12:53 [debug    ] train_step                     loss=-2.978391 lr=9.89e-05 step=7750\n",
            "2026-02-19 10:12:54 [debug    ] train_step                     loss=-3.100201 lr=9.89e-05 step=7800\n",
            "2026-02-19 10:12:54 [debug    ] train_step                     loss=-3.109487 lr=9.88e-05 step=7850\n",
            "2026-02-19 10:12:55 [debug    ] train_step                     loss=-2.722068 lr=9.88e-05 step=7900\n",
            "2026-02-19 10:12:55 [debug    ] train_step                     loss=-2.979157 lr=9.88e-05 step=7950\n",
            "2026-02-19 10:12:56 [debug    ] train_step                     loss=-3.174136 lr=9.88e-05 step=8000\n",
            "2026-02-19 10:12:57 [info     ] epoch_complete                 epoch=8 lr=9.88e-05 train_loss=-3.015323 val_loss=-3.280744\n",
            "2026-02-19 10:12:57 [info     ] checkpoint_saved               epoch=7 path=best.pt score=-3.2807439171661765\n",
            "2026-02-19 10:12:57 [debug    ] train_step                     loss=-3.011997 lr=9.88e-05 step=8050\n",
            "2026-02-19 10:12:57 [debug    ] train_step                     loss=-3.126427 lr=9.88e-05 step=8100\n",
            "2026-02-19 10:12:58 [debug    ] train_step                     loss=-3.091368 lr=9.87e-05 step=8150\n",
            "2026-02-19 10:12:58 [debug    ] train_step                     loss=-3.225189 lr=9.87e-05 step=8200\n",
            "2026-02-19 10:12:59 [debug    ] train_step                     loss=-3.168842 lr=9.87e-05 step=8250\n",
            "2026-02-19 10:13:00 [debug    ] train_step                     loss=-2.997938 lr=9.87e-05 step=8300\n",
            "2026-02-19 10:13:00 [debug    ] train_step                     loss=-3.131248 lr=9.87e-05 step=8350\n",
            "2026-02-19 10:13:01 [debug    ] train_step                     loss=-3.022464 lr=9.87e-05 step=8400\n",
            "2026-02-19 10:13:01 [debug    ] train_step                     loss=-2.893954 lr=9.86e-05 step=8450\n",
            "2026-02-19 10:13:02 [debug    ] train_step                     loss=-2.841365 lr=9.86e-05 step=8500\n",
            "2026-02-19 10:13:02 [debug    ] train_step                     loss=-3.168703 lr=9.86e-05 step=8550\n",
            "2026-02-19 10:13:03 [debug    ] train_step                     loss=-3.047014 lr=9.86e-05 step=8600\n",
            "2026-02-19 10:13:03 [debug    ] train_step                     loss=-3.213236 lr=9.86e-05 step=8650\n",
            "2026-02-19 10:13:04 [debug    ] train_step                     loss=-3.115718 lr=9.85e-05 step=8700\n",
            "2026-02-19 10:13:04 [debug    ] train_step                     loss=-2.956205 lr=9.85e-05 step=8750\n",
            "2026-02-19 10:13:05 [debug    ] train_step                     loss=-2.963333 lr=9.85e-05 step=8800\n",
            "2026-02-19 10:13:05 [debug    ] train_step                     loss=-3.249326 lr=9.85e-05 step=8850\n",
            "2026-02-19 10:13:06 [debug    ] train_step                     loss=-3.053423 lr=9.85e-05 step=8900\n",
            "2026-02-19 10:13:06 [debug    ] train_step                     loss=-2.737061 lr=9.84e-05 step=8950\n",
            "2026-02-19 10:13:07 [debug    ] train_step                     loss=-3.132180 lr=9.84e-05 step=9000\n",
            "2026-02-19 10:13:08 [info     ] epoch_complete                 epoch=9 lr=9.84e-05 train_loss=-3.032244 val_loss=-3.279972\n",
            "2026-02-19 10:13:08 [debug    ] train_step                     loss=-3.139896 lr=9.84e-05 step=9050\n",
            "2026-02-19 10:13:09 [debug    ] train_step                     loss=-3.191261 lr=9.84e-05 step=9100\n",
            "2026-02-19 10:13:09 [debug    ] train_step                     loss=-3.099199 lr=9.84e-05 step=9150\n",
            "2026-02-19 10:13:10 [debug    ] train_step                     loss=-2.713652 lr=9.84e-05 step=9200\n",
            "2026-02-19 10:13:10 [debug    ] train_step                     loss=-3.010415 lr=9.83e-05 step=9250\n",
            "2026-02-19 10:13:11 [debug    ] train_step                     loss=-3.076056 lr=9.83e-05 step=9300\n",
            "2026-02-19 10:13:11 [debug    ] train_step                     loss=-2.877547 lr=9.83e-05 step=9350\n",
            "2026-02-19 10:13:12 [debug    ] train_step                     loss=-3.007595 lr=9.83e-05 step=9400\n",
            "2026-02-19 10:13:12 [debug    ] train_step                     loss=-3.094668 lr=9.82e-05 step=9450\n",
            "2026-02-19 10:13:13 [debug    ] train_step                     loss=-3.111309 lr=9.82e-05 step=9500\n",
            "2026-02-19 10:13:13 [debug    ] train_step                     loss=-3.264841 lr=9.82e-05 step=9550\n",
            "2026-02-19 10:13:14 [debug    ] train_step                     loss=-2.969806 lr=9.82e-05 step=9600\n",
            "2026-02-19 10:13:14 [debug    ] train_step                     loss=-2.915213 lr=9.82e-05 step=9650\n",
            "2026-02-19 10:13:15 [debug    ] train_step                     loss=-3.106560 lr=9.81e-05 step=9700\n",
            "2026-02-19 10:13:15 [debug    ] train_step                     loss=-2.750056 lr=9.81e-05 step=9750\n",
            "2026-02-19 10:13:16 [debug    ] train_step                     loss=-3.058614 lr=9.81e-05 step=9800\n",
            "2026-02-19 10:13:16 [debug    ] train_step                     loss=-2.995608 lr=9.81e-05 step=9850\n",
            "2026-02-19 10:13:17 [debug    ] train_step                     loss=-3.314854 lr=9.81e-05 step=9900\n",
            "2026-02-19 10:13:18 [debug    ] train_step                     loss=-3.237932 lr=9.80e-05 step=9950\n",
            "2026-02-19 10:13:18 [debug    ] train_step                     loss=-3.006301 lr=9.80e-05 step=10000\n",
            "2026-02-19 10:13:19 [debug    ] train_step                     loss=-3.151277 lr=9.80e-05 step=10050\n",
            "2026-02-19 10:13:19 [info     ] epoch_complete                 epoch=10 lr=9.80e-05 train_loss=-3.040750 val_loss=-3.285017\n",
            "2026-02-19 10:13:19 [info     ] checkpoint_saved               epoch=9 path=best.pt score=-3.285016892320019\n",
            "2026-02-19 10:13:20 [debug    ] train_step                     loss=-2.843029 lr=9.80e-05 step=10100\n",
            "2026-02-19 10:13:20 [debug    ] train_step                     loss=-3.072664 lr=9.79e-05 step=10150\n",
            "2026-02-19 10:13:21 [debug    ] train_step                     loss=-3.127075 lr=9.79e-05 step=10200\n",
            "2026-02-19 10:13:21 [debug    ] train_step                     loss=-3.144886 lr=9.79e-05 step=10250\n",
            "2026-02-19 10:13:22 [debug    ] train_step                     loss=-3.063505 lr=9.79e-05 step=10300\n",
            "2026-02-19 10:13:23 [debug    ] train_step                     loss=-2.759938 lr=9.79e-05 step=10350\n",
            "2026-02-19 10:13:23 [debug    ] train_step                     loss=-3.157689 lr=9.78e-05 step=10400\n",
            "2026-02-19 10:13:24 [debug    ] train_step                     loss=-2.977896 lr=9.78e-05 step=10450\n",
            "2026-02-19 10:13:24 [debug    ] train_step                     loss=-3.034400 lr=9.78e-05 step=10500\n",
            "2026-02-19 10:13:25 [debug    ] train_step                     loss=-3.107466 lr=9.78e-05 step=10550\n",
            "2026-02-19 10:13:25 [debug    ] train_step                     loss=-3.171817 lr=9.77e-05 step=10600\n",
            "2026-02-19 10:13:26 [debug    ] train_step                     loss=-3.032965 lr=9.77e-05 step=10650\n",
            "2026-02-19 10:13:26 [debug    ] train_step                     loss=-3.032436 lr=9.77e-05 step=10700\n",
            "2026-02-19 10:13:27 [debug    ] train_step                     loss=-3.155843 lr=9.77e-05 step=10750\n",
            "2026-02-19 10:13:27 [debug    ] train_step                     loss=-3.126573 lr=9.76e-05 step=10800\n",
            "2026-02-19 10:13:28 [debug    ] train_step                     loss=-3.211330 lr=9.76e-05 step=10850\n",
            "2026-02-19 10:13:28 [debug    ] train_step                     loss=-3.154874 lr=9.76e-05 step=10900\n",
            "2026-02-19 10:13:29 [debug    ] train_step                     loss=-3.119891 lr=9.76e-05 step=10950\n",
            "2026-02-19 10:13:29 [debug    ] train_step                     loss=-2.959452 lr=9.76e-05 step=11000\n",
            "2026-02-19 10:13:30 [debug    ] train_step                     loss=-3.079315 lr=9.75e-05 step=11050\n",
            "2026-02-19 10:13:30 [info     ] epoch_complete                 epoch=11 lr=9.75e-05 train_loss=-3.053577 val_loss=-3.266865\n",
            "2026-02-19 10:13:31 [debug    ] train_step                     loss=-3.226700 lr=9.75e-05 step=11100\n",
            "2026-02-19 10:13:32 [debug    ] train_step                     loss=-3.189826 lr=9.75e-05 step=11150\n",
            "2026-02-19 10:13:32 [debug    ] train_step                     loss=-3.192016 lr=9.75e-05 step=11200\n",
            "2026-02-19 10:13:33 [debug    ] train_step                     loss=-3.055891 lr=9.74e-05 step=11250\n",
            "2026-02-19 10:13:33 [debug    ] train_step                     loss=-3.132480 lr=9.74e-05 step=11300\n",
            "2026-02-19 10:13:34 [debug    ] train_step                     loss=-3.149790 lr=9.74e-05 step=11350\n",
            "2026-02-19 10:13:34 [debug    ] train_step                     loss=-3.127160 lr=9.74e-05 step=11400\n",
            "2026-02-19 10:13:35 [debug    ] train_step                     loss=-3.142440 lr=9.73e-05 step=11450\n",
            "2026-02-19 10:13:35 [debug    ] train_step                     loss=-3.188236 lr=9.73e-05 step=11500\n",
            "2026-02-19 10:13:36 [debug    ] train_step                     loss=-3.100503 lr=9.73e-05 step=11550\n",
            "2026-02-19 10:13:36 [debug    ] train_step                     loss=-3.134206 lr=9.73e-05 step=11600\n",
            "2026-02-19 10:13:37 [debug    ] train_step                     loss=-2.999039 lr=9.72e-05 step=11650\n",
            "2026-02-19 10:13:37 [debug    ] train_step                     loss=-3.120559 lr=9.72e-05 step=11700\n",
            "2026-02-19 10:13:38 [debug    ] train_step                     loss=-3.136157 lr=9.72e-05 step=11750\n",
            "2026-02-19 10:13:38 [debug    ] train_step                     loss=-2.702698 lr=9.71e-05 step=11800\n",
            "2026-02-19 10:13:39 [debug    ] train_step                     loss=-2.981840 lr=9.71e-05 step=11850\n",
            "2026-02-19 10:13:39 [debug    ] train_step                     loss=-2.822677 lr=9.71e-05 step=11900\n",
            "2026-02-19 10:13:40 [debug    ] train_step                     loss=-2.995632 lr=9.71e-05 step=11950\n",
            "2026-02-19 10:13:40 [debug    ] train_step                     loss=-2.965703 lr=9.70e-05 step=12000\n",
            "2026-02-19 10:13:41 [debug    ] train_step                     loss=-3.032273 lr=9.70e-05 step=12050\n",
            "2026-02-19 10:13:41 [info     ] epoch_complete                 epoch=12 lr=9.70e-05 train_loss=-3.060555 val_loss=-3.244621\n",
            "2026-02-19 10:13:42 [debug    ] train_step                     loss=-3.140139 lr=9.70e-05 step=12100\n",
            "2026-02-19 10:13:43 [debug    ] train_step                     loss=-3.225885 lr=9.70e-05 step=12150\n",
            "2026-02-19 10:13:43 [debug    ] train_step                     loss=-2.881819 lr=9.69e-05 step=12200\n",
            "2026-02-19 10:13:44 [debug    ] train_step                     loss=-3.257261 lr=9.69e-05 step=12250\n",
            "2026-02-19 10:13:44 [debug    ] train_step                     loss=-2.991362 lr=9.69e-05 step=12300\n",
            "2026-02-19 10:13:45 [debug    ] train_step                     loss=-2.807426 lr=9.69e-05 step=12350\n",
            "2026-02-19 10:13:45 [debug    ] train_step                     loss=-2.993715 lr=9.68e-05 step=12400\n",
            "2026-02-19 10:13:46 [debug    ] train_step                     loss=-3.035812 lr=9.68e-05 step=12450\n",
            "2026-02-19 10:13:46 [debug    ] train_step                     loss=-3.134724 lr=9.68e-05 step=12500\n",
            "2026-02-19 10:13:47 [debug    ] train_step                     loss=-3.112047 lr=9.67e-05 step=12550\n",
            "2026-02-19 10:13:47 [debug    ] train_step                     loss=-3.027461 lr=9.67e-05 step=12600\n",
            "2026-02-19 10:13:48 [debug    ] train_step                     loss=-3.113314 lr=9.67e-05 step=12650\n",
            "2026-02-19 10:13:48 [debug    ] train_step                     loss=-3.004386 lr=9.67e-05 step=12700\n",
            "2026-02-19 10:13:49 [debug    ] train_step                     loss=-3.016059 lr=9.66e-05 step=12750\n",
            "2026-02-19 10:13:49 [debug    ] train_step                     loss=-3.149430 lr=9.66e-05 step=12800\n",
            "2026-02-19 10:13:50 [debug    ] train_step                     loss=-3.097068 lr=9.66e-05 step=12850\n",
            "2026-02-19 10:13:50 [debug    ] train_step                     loss=-3.016569 lr=9.65e-05 step=12900\n",
            "2026-02-19 10:13:51 [debug    ] train_step                     loss=-3.131468 lr=9.65e-05 step=12950\n",
            "2026-02-19 10:13:51 [debug    ] train_step                     loss=-3.180274 lr=9.65e-05 step=13000\n",
            "2026-02-19 10:13:52 [debug    ] train_step                     loss=-3.095081 lr=9.65e-05 step=13050\n",
            "2026-02-19 10:13:53 [info     ] epoch_complete                 epoch=13 lr=9.65e-05 train_loss=-3.072873 val_loss=-3.275413\n",
            "2026-02-19 10:13:53 [debug    ] train_step                     loss=-3.102989 lr=9.64e-05 step=13100\n",
            "2026-02-19 10:13:54 [debug    ] train_step                     loss=-3.175949 lr=9.64e-05 step=13150\n",
            "2026-02-19 10:13:54 [debug    ] train_step                     loss=-3.079183 lr=9.64e-05 step=13200\n",
            "2026-02-19 10:13:55 [debug    ] train_step                     loss=-2.822944 lr=9.63e-05 step=13250\n",
            "2026-02-19 10:13:55 [debug    ] train_step                     loss=-3.169468 lr=9.63e-05 step=13300\n",
            "2026-02-19 10:13:56 [debug    ] train_step                     loss=-3.125888 lr=9.63e-05 step=13350\n",
            "2026-02-19 10:13:56 [debug    ] train_step                     loss=-2.826273 lr=9.63e-05 step=13400\n",
            "2026-02-19 10:13:57 [debug    ] train_step                     loss=-2.962358 lr=9.62e-05 step=13450\n",
            "2026-02-19 10:13:57 [debug    ] train_step                     loss=-3.090118 lr=9.62e-05 step=13500\n",
            "2026-02-19 10:13:58 [debug    ] train_step                     loss=-3.016235 lr=9.62e-05 step=13550\n",
            "2026-02-19 10:13:58 [debug    ] train_step                     loss=-3.013022 lr=9.61e-05 step=13600\n",
            "2026-02-19 10:13:59 [debug    ] train_step                     loss=-3.191446 lr=9.61e-05 step=13650\n",
            "2026-02-19 10:13:59 [debug    ] train_step                     loss=-3.161191 lr=9.61e-05 step=13700\n",
            "2026-02-19 10:14:00 [debug    ] train_step                     loss=-3.179193 lr=9.60e-05 step=13750\n",
            "2026-02-19 10:14:00 [debug    ] train_step                     loss=-3.035568 lr=9.60e-05 step=13800\n",
            "2026-02-19 10:14:01 [debug    ] train_step                     loss=-2.851411 lr=9.60e-05 step=13850\n",
            "2026-02-19 10:14:01 [debug    ] train_step                     loss=-3.277392 lr=9.60e-05 step=13900\n",
            "2026-02-19 10:14:02 [debug    ] train_step                     loss=-3.016464 lr=9.59e-05 step=13950\n",
            "2026-02-19 10:14:03 [debug    ] train_step                     loss=-3.003168 lr=9.59e-05 step=14000\n",
            "2026-02-19 10:14:03 [debug    ] train_step                     loss=-3.082726 lr=9.59e-05 step=14050\n",
            "2026-02-19 10:14:04 [info     ] epoch_complete                 epoch=14 lr=9.58e-05 train_loss=-3.071406 val_loss=-3.287902\n",
            "2026-02-19 10:14:04 [info     ] checkpoint_saved               epoch=13 path=best.pt score=-3.287901722778708\n",
            "2026-02-19 10:14:04 [debug    ] train_step                     loss=-3.136038 lr=9.58e-05 step=14100\n",
            "2026-02-19 10:14:05 [debug    ] train_step                     loss=-2.992878 lr=9.58e-05 step=14150\n",
            "2026-02-19 10:14:05 [debug    ] train_step                     loss=-2.957494 lr=9.58e-05 step=14200\n",
            "2026-02-19 10:14:06 [debug    ] train_step                     loss=-2.874782 lr=9.57e-05 step=14250\n",
            "2026-02-19 10:14:06 [debug    ] train_step                     loss=-3.126539 lr=9.57e-05 step=14300\n",
            "2026-02-19 10:14:07 [debug    ] train_step                     loss=-3.223620 lr=9.57e-05 step=14350\n",
            "2026-02-19 10:14:07 [debug    ] train_step                     loss=-3.039461 lr=9.56e-05 step=14400\n",
            "2026-02-19 10:14:08 [debug    ] train_step                     loss=-3.028632 lr=9.56e-05 step=14450\n",
            "2026-02-19 10:14:08 [debug    ] train_step                     loss=-3.070162 lr=9.56e-05 step=14500\n",
            "2026-02-19 10:14:09 [debug    ] train_step                     loss=-2.724187 lr=9.55e-05 step=14550\n",
            "2026-02-19 10:14:10 [debug    ] train_step                     loss=-3.062511 lr=9.55e-05 step=14600\n",
            "2026-02-19 10:14:10 [debug    ] train_step                     loss=-3.137072 lr=9.55e-05 step=14650\n",
            "2026-02-19 10:14:11 [debug    ] train_step                     loss=-2.701168 lr=9.54e-05 step=14700\n",
            "2026-02-19 10:14:11 [debug    ] train_step                     loss=-2.761853 lr=9.54e-05 step=14750\n",
            "2026-02-19 10:14:12 [debug    ] train_step                     loss=-3.165474 lr=9.54e-05 step=14800\n",
            "2026-02-19 10:14:12 [debug    ] train_step                     loss=-3.142211 lr=9.53e-05 step=14850\n",
            "2026-02-19 10:14:13 [debug    ] train_step                     loss=-3.072148 lr=9.53e-05 step=14900\n",
            "2026-02-19 10:14:13 [debug    ] train_step                     loss=-3.109670 lr=9.53e-05 step=14950\n",
            "2026-02-19 10:14:14 [debug    ] train_step                     loss=-2.728080 lr=9.52e-05 step=15000\n",
            "2026-02-19 10:14:14 [debug    ] train_step                     loss=-3.231353 lr=9.52e-05 step=15050\n",
            "2026-02-19 10:14:15 [info     ] epoch_complete                 epoch=15 lr=9.52e-05 train_loss=-3.071257 val_loss=-3.299695\n",
            "2026-02-19 10:14:15 [info     ] checkpoint_saved               epoch=14 path=best.pt score=-3.2996953836942122\n",
            "2026-02-19 10:14:15 [debug    ] train_step                     loss=-3.161353 lr=9.52e-05 step=15100\n",
            "2026-02-19 10:14:16 [debug    ] train_step                     loss=-3.090155 lr=9.51e-05 step=15150\n",
            "2026-02-19 10:14:16 [debug    ] train_step                     loss=-3.185398 lr=9.51e-05 step=15200\n",
            "2026-02-19 10:14:17 [debug    ] train_step                     loss=-3.079508 lr=9.51e-05 step=15250\n",
            "2026-02-19 10:14:18 [debug    ] train_step                     loss=-3.203752 lr=9.50e-05 step=15300\n",
            "2026-02-19 10:14:18 [debug    ] train_step                     loss=-2.945918 lr=9.50e-05 step=15350\n",
            "2026-02-19 10:14:19 [debug    ] train_step                     loss=-3.218450 lr=9.50e-05 step=15400\n",
            "2026-02-19 10:14:19 [debug    ] train_step                     loss=-3.103945 lr=9.49e-05 step=15450\n",
            "2026-02-19 10:14:20 [debug    ] train_step                     loss=-3.124051 lr=9.49e-05 step=15500\n",
            "2026-02-19 10:14:20 [debug    ] train_step                     loss=-3.043314 lr=9.49e-05 step=15550\n",
            "2026-02-19 10:14:21 [debug    ] train_step                     loss=-3.250222 lr=9.48e-05 step=15600\n",
            "2026-02-19 10:14:21 [debug    ] train_step                     loss=-3.133992 lr=9.48e-05 step=15650\n",
            "2026-02-19 10:14:22 [debug    ] train_step                     loss=-3.162529 lr=9.48e-05 step=15700\n",
            "2026-02-19 10:14:22 [debug    ] train_step                     loss=-2.956283 lr=9.47e-05 step=15750\n",
            "2026-02-19 10:14:23 [debug    ] train_step                     loss=-2.897106 lr=9.47e-05 step=15800\n",
            "2026-02-19 10:14:23 [debug    ] train_step                     loss=-3.145055 lr=9.47e-05 step=15850\n",
            "2026-02-19 10:14:24 [debug    ] train_step                     loss=-2.987436 lr=9.46e-05 step=15900\n",
            "2026-02-19 10:14:24 [debug    ] train_step                     loss=-3.193866 lr=9.46e-05 step=15950\n",
            "2026-02-19 10:14:25 [debug    ] train_step                     loss=-3.120499 lr=9.46e-05 step=16000\n",
            "2026-02-19 10:14:25 [debug    ] train_step                     loss=-3.081931 lr=9.45e-05 step=16050\n",
            "2026-02-19 10:14:26 [info     ] epoch_complete                 epoch=16 lr=9.45e-05 train_loss=-3.091072 val_loss=-3.262468\n",
            "2026-02-19 10:14:27 [debug    ] train_step                     loss=-2.884346 lr=9.45e-05 step=16100\n",
            "2026-02-19 10:14:27 [debug    ] train_step                     loss=-3.163209 lr=9.44e-05 step=16150\n",
            "2026-02-19 10:14:28 [debug    ] train_step                     loss=-3.140208 lr=9.44e-05 step=16200\n",
            "2026-02-19 10:14:28 [debug    ] train_step                     loss=-2.999094 lr=9.44e-05 step=16250\n",
            "2026-02-19 10:14:29 [debug    ] train_step                     loss=-3.153908 lr=9.43e-05 step=16300\n",
            "2026-02-19 10:14:29 [debug    ] train_step                     loss=-2.978901 lr=9.43e-05 step=16350\n",
            "2026-02-19 10:14:30 [debug    ] train_step                     loss=-3.146506 lr=9.43e-05 step=16400\n",
            "2026-02-19 10:14:30 [debug    ] train_step                     loss=-3.012529 lr=9.42e-05 step=16450\n",
            "2026-02-19 10:14:31 [debug    ] train_step                     loss=-3.140713 lr=9.42e-05 step=16500\n",
            "2026-02-19 10:14:31 [debug    ] train_step                     loss=-2.987090 lr=9.42e-05 step=16550\n",
            "2026-02-19 10:14:32 [debug    ] train_step                     loss=-2.975204 lr=9.41e-05 step=16600\n",
            "2026-02-19 10:14:32 [debug    ] train_step                     loss=-3.222322 lr=9.41e-05 step=16650\n",
            "2026-02-19 10:14:33 [debug    ] train_step                     loss=-3.014594 lr=9.40e-05 step=16700\n",
            "2026-02-19 10:14:33 [debug    ] train_step                     loss=-3.141362 lr=9.40e-05 step=16750\n",
            "2026-02-19 10:14:34 [debug    ] train_step                     loss=-3.194389 lr=9.40e-05 step=16800\n",
            "2026-02-19 10:14:34 [debug    ] train_step                     loss=-3.230844 lr=9.39e-05 step=16850\n",
            "2026-02-19 10:14:35 [debug    ] train_step                     loss=-3.141922 lr=9.39e-05 step=16900\n",
            "2026-02-19 10:14:35 [debug    ] train_step                     loss=-3.084608 lr=9.39e-05 step=16950\n",
            "2026-02-19 10:14:36 [debug    ] train_step                     loss=-3.032409 lr=9.38e-05 step=17000\n",
            "2026-02-19 10:14:36 [debug    ] train_step                     loss=-2.978827 lr=9.38e-05 step=17050\n",
            "2026-02-19 10:14:37 [info     ] epoch_complete                 epoch=17 lr=9.38e-05 train_loss=-3.082519 val_loss=-3.269875\n",
            "2026-02-19 10:14:38 [debug    ] train_step                     loss=-3.123025 lr=9.37e-05 step=17100\n",
            "2026-02-19 10:14:38 [debug    ] train_step                     loss=-3.041832 lr=9.37e-05 step=17150\n",
            "2026-02-19 10:14:39 [debug    ] train_step                     loss=-3.001617 lr=9.37e-05 step=17200\n",
            "2026-02-19 10:14:39 [debug    ] train_step                     loss=-3.097245 lr=9.36e-05 step=17250\n",
            "2026-02-19 10:14:40 [debug    ] train_step                     loss=-3.105382 lr=9.36e-05 step=17300\n",
            "2026-02-19 10:14:40 [debug    ] train_step                     loss=-2.906099 lr=9.35e-05 step=17350\n",
            "2026-02-19 10:14:41 [debug    ] train_step                     loss=-3.027749 lr=9.35e-05 step=17400\n",
            "2026-02-19 10:14:41 [debug    ] train_step                     loss=-3.040967 lr=9.35e-05 step=17450\n",
            "2026-02-19 10:14:42 [debug    ] train_step                     loss=-2.985320 lr=9.34e-05 step=17500\n",
            "2026-02-19 10:14:42 [debug    ] train_step                     loss=-2.876852 lr=9.34e-05 step=17550\n",
            "2026-02-19 10:14:43 [debug    ] train_step                     loss=-3.188258 lr=9.34e-05 step=17600\n",
            "2026-02-19 10:14:43 [debug    ] train_step                     loss=-3.064458 lr=9.33e-05 step=17650\n",
            "2026-02-19 10:14:44 [debug    ] train_step                     loss=-2.888420 lr=9.33e-05 step=17700\n",
            "2026-02-19 10:14:44 [debug    ] train_step                     loss=-3.127910 lr=9.32e-05 step=17750\n",
            "2026-02-19 10:14:45 [debug    ] train_step                     loss=-3.248554 lr=9.32e-05 step=17800\n",
            "2026-02-19 10:14:45 [debug    ] train_step                     loss=-3.215088 lr=9.32e-05 step=17850\n",
            "2026-02-19 10:14:46 [debug    ] train_step                     loss=-3.140491 lr=9.31e-05 step=17900\n",
            "2026-02-19 10:14:47 [debug    ] train_step                     loss=-3.137250 lr=9.31e-05 step=17950\n",
            "2026-02-19 10:14:47 [debug    ] train_step                     loss=-2.950381 lr=9.30e-05 step=18000\n",
            "2026-02-19 10:14:48 [debug    ] train_step                     loss=-3.133561 lr=9.30e-05 step=18050\n",
            "2026-02-19 10:14:48 [info     ] epoch_complete                 epoch=18 lr=9.30e-05 train_loss=-3.096976 val_loss=-3.305487\n",
            "2026-02-19 10:14:49 [info     ] checkpoint_saved               epoch=17 path=best.pt score=-3.3054871033813993\n",
            "2026-02-19 10:14:49 [debug    ] train_step                     loss=-3.142282 lr=9.30e-05 step=18100\n",
            "2026-02-19 10:14:49 [debug    ] train_step                     loss=-3.195601 lr=9.29e-05 step=18150\n",
            "2026-02-19 10:14:50 [debug    ] train_step                     loss=-3.197052 lr=9.29e-05 step=18200\n",
            "2026-02-19 10:14:50 [debug    ] train_step                     loss=-3.119598 lr=9.28e-05 step=18250\n",
            "2026-02-19 10:14:51 [debug    ] train_step                     loss=-3.231897 lr=9.28e-05 step=18300\n",
            "2026-02-19 10:14:51 [debug    ] train_step                     loss=-3.133570 lr=9.28e-05 step=18350\n",
            "2026-02-19 10:14:52 [debug    ] train_step                     loss=-3.079867 lr=9.27e-05 step=18400\n",
            "2026-02-19 10:14:52 [debug    ] train_step                     loss=-2.976274 lr=9.27e-05 step=18450\n",
            "2026-02-19 10:14:53 [debug    ] train_step                     loss=-3.191180 lr=9.26e-05 step=18500\n",
            "2026-02-19 10:14:54 [debug    ] train_step                     loss=-3.095788 lr=9.26e-05 step=18550\n",
            "2026-02-19 10:14:54 [debug    ] train_step                     loss=-3.099667 lr=9.26e-05 step=18600\n",
            "2026-02-19 10:14:55 [debug    ] train_step                     loss=-3.164143 lr=9.25e-05 step=18650\n",
            "2026-02-19 10:14:55 [debug    ] train_step                     loss=-3.157328 lr=9.25e-05 step=18700\n",
            "2026-02-19 10:14:56 [debug    ] train_step                     loss=-2.891176 lr=9.24e-05 step=18750\n",
            "2026-02-19 10:14:56 [debug    ] train_step                     loss=-3.272932 lr=9.24e-05 step=18800\n",
            "2026-02-19 10:14:57 [debug    ] train_step                     loss=-3.066694 lr=9.23e-05 step=18850\n",
            "2026-02-19 10:14:57 [debug    ] train_step                     loss=-3.182755 lr=9.23e-05 step=18900\n",
            "2026-02-19 10:14:58 [debug    ] train_step                     loss=-2.910851 lr=9.23e-05 step=18950\n",
            "2026-02-19 10:14:58 [debug    ] train_step                     loss=-3.010668 lr=9.22e-05 step=19000\n",
            "2026-02-19 10:14:59 [debug    ] train_step                     loss=-3.096571 lr=9.22e-05 step=19050\n",
            "2026-02-19 10:15:00 [info     ] epoch_complete                 epoch=19 lr=9.21e-05 train_loss=-3.100837 val_loss=-3.269234\n",
            "2026-02-19 10:15:00 [debug    ] train_step                     loss=-3.146541 lr=9.21e-05 step=19100\n",
            "2026-02-19 10:15:00 [debug    ] train_step                     loss=-3.185726 lr=9.21e-05 step=19150\n",
            "2026-02-19 10:15:01 [debug    ] train_step                     loss=-3.056476 lr=9.20e-05 step=19200\n",
            "2026-02-19 10:15:01 [debug    ] train_step                     loss=-2.332416 lr=9.20e-05 step=19250\n",
            "2026-02-19 10:15:02 [debug    ] train_step                     loss=-3.270029 lr=9.20e-05 step=19300\n",
            "2026-02-19 10:15:02 [debug    ] train_step                     loss=-2.769489 lr=9.19e-05 step=19350\n",
            "2026-02-19 10:15:03 [debug    ] train_step                     loss=-3.124581 lr=9.19e-05 step=19400\n",
            "2026-02-19 10:15:04 [debug    ] train_step                     loss=-2.899802 lr=9.18e-05 step=19450\n",
            "2026-02-19 10:15:04 [debug    ] train_step                     loss=-3.114961 lr=9.18e-05 step=19500\n",
            "2026-02-19 10:15:05 [debug    ] train_step                     loss=-3.166596 lr=9.17e-05 step=19550\n",
            "2026-02-19 10:15:05 [debug    ] train_step                     loss=-3.042119 lr=9.17e-05 step=19600\n",
            "2026-02-19 10:15:06 [debug    ] train_step                     loss=-3.304052 lr=9.17e-05 step=19650\n",
            "2026-02-19 10:15:06 [debug    ] train_step                     loss=-3.221251 lr=9.16e-05 step=19700\n",
            "2026-02-19 10:15:07 [debug    ] train_step                     loss=-3.075378 lr=9.16e-05 step=19750\n",
            "2026-02-19 10:15:07 [debug    ] train_step                     loss=-3.190732 lr=9.15e-05 step=19800\n",
            "2026-02-19 10:15:08 [debug    ] train_step                     loss=-3.151500 lr=9.15e-05 step=19850\n",
            "2026-02-19 10:15:08 [debug    ] train_step                     loss=-3.139466 lr=9.14e-05 step=19900\n",
            "2026-02-19 10:15:09 [debug    ] train_step                     loss=-3.142365 lr=9.14e-05 step=19950\n",
            "2026-02-19 10:15:09 [debug    ] train_step                     loss=-3.037011 lr=9.14e-05 step=20000\n",
            "2026-02-19 10:15:10 [debug    ] train_step                     loss=-3.002853 lr=9.13e-05 step=20050\n",
            "2026-02-19 10:15:10 [debug    ] train_step                     loss=-2.914698 lr=9.13e-05 step=20100\n",
            "2026-02-19 10:15:11 [info     ] epoch_complete                 epoch=20 lr=9.13e-05 train_loss=-3.105393 val_loss=-3.274880\n",
            "2026-02-19 10:15:11 [debug    ] train_step                     loss=-3.186863 lr=9.12e-05 step=20150\n",
            "2026-02-19 10:15:12 [debug    ] train_step                     loss=-3.191956 lr=9.12e-05 step=20200\n",
            "2026-02-19 10:15:13 [debug    ] train_step                     loss=-3.139156 lr=9.11e-05 step=20250\n",
            "2026-02-19 10:15:13 [debug    ] train_step                     loss=-3.136209 lr=9.11e-05 step=20300\n",
            "2026-02-19 10:15:14 [debug    ] train_step                     loss=-3.169915 lr=9.10e-05 step=20350\n",
            "2026-02-19 10:15:14 [debug    ] train_step                     loss=-3.206400 lr=9.10e-05 step=20400\n",
            "2026-02-19 10:15:15 [debug    ] train_step                     loss=-3.068736 lr=9.10e-05 step=20450\n",
            "2026-02-19 10:15:15 [debug    ] train_step                     loss=-3.031790 lr=9.09e-05 step=20500\n",
            "2026-02-19 10:15:16 [debug    ] train_step                     loss=-2.851802 lr=9.09e-05 step=20550\n",
            "2026-02-19 10:15:16 [debug    ] train_step                     loss=-3.361531 lr=9.08e-05 step=20600\n",
            "2026-02-19 10:15:17 [debug    ] train_step                     loss=-2.807490 lr=9.08e-05 step=20650\n",
            "2026-02-19 10:15:17 [debug    ] train_step                     loss=-3.168243 lr=9.07e-05 step=20700\n",
            "2026-02-19 10:15:18 [debug    ] train_step                     loss=-3.025689 lr=9.07e-05 step=20750\n",
            "2026-02-19 10:15:18 [debug    ] train_step                     loss=-3.026698 lr=9.06e-05 step=20800\n",
            "2026-02-19 10:15:19 [debug    ] train_step                     loss=-3.065679 lr=9.06e-05 step=20850\n",
            "2026-02-19 10:15:20 [debug    ] train_step                     loss=-3.074981 lr=9.05e-05 step=20900\n",
            "2026-02-19 10:15:20 [debug    ] train_step                     loss=-3.179415 lr=9.05e-05 step=20950\n",
            "2026-02-19 10:15:21 [debug    ] train_step                     loss=-2.994801 lr=9.05e-05 step=21000\n",
            "2026-02-19 10:15:21 [debug    ] train_step                     loss=-3.185723 lr=9.04e-05 step=21050\n",
            "2026-02-19 10:15:22 [debug    ] train_step                     loss=-3.121204 lr=9.04e-05 step=21100\n",
            "2026-02-19 10:15:22 [info     ] epoch_complete                 epoch=21 lr=9.04e-05 train_loss=-3.107566 val_loss=-3.263219\n",
            "2026-02-19 10:15:23 [debug    ] train_step                     loss=-3.161150 lr=9.03e-05 step=21150\n",
            "2026-02-19 10:15:23 [debug    ] train_step                     loss=-3.095937 lr=9.03e-05 step=21200\n",
            "2026-02-19 10:15:24 [debug    ] train_step                     loss=-2.966275 lr=9.02e-05 step=21250\n",
            "2026-02-19 10:15:24 [debug    ] train_step                     loss=-3.058347 lr=9.02e-05 step=21300\n",
            "2026-02-19 10:15:25 [debug    ] train_step                     loss=-3.073692 lr=9.01e-05 step=21350\n",
            "2026-02-19 10:15:25 [debug    ] train_step                     loss=-3.145618 lr=9.01e-05 step=21400\n",
            "2026-02-19 10:15:26 [debug    ] train_step                     loss=-3.186646 lr=9.00e-05 step=21450\n",
            "2026-02-19 10:15:26 [debug    ] train_step                     loss=-3.117370 lr=9.00e-05 step=21500\n",
            "2026-02-19 10:15:27 [debug    ] train_step                     loss=-3.180968 lr=8.99e-05 step=21550\n",
            "2026-02-19 10:15:28 [debug    ] train_step                     loss=-3.159956 lr=8.99e-05 step=21600\n",
            "2026-02-19 10:15:28 [debug    ] train_step                     loss=-3.031516 lr=8.98e-05 step=21650\n",
            "2026-02-19 10:15:29 [debug    ] train_step                     loss=-3.180163 lr=8.98e-05 step=21700\n",
            "2026-02-19 10:15:29 [debug    ] train_step                     loss=-2.978132 lr=8.98e-05 step=21750\n",
            "2026-02-19 10:15:30 [debug    ] train_step                     loss=-3.064099 lr=8.97e-05 step=21800\n",
            "2026-02-19 10:15:30 [debug    ] train_step                     loss=-3.292002 lr=8.97e-05 step=21850\n",
            "2026-02-19 10:15:31 [debug    ] train_step                     loss=-3.105956 lr=8.96e-05 step=21900\n",
            "2026-02-19 10:15:31 [debug    ] train_step                     loss=-3.180324 lr=8.96e-05 step=21950\n",
            "2026-02-19 10:15:32 [debug    ] train_step                     loss=-3.164190 lr=8.95e-05 step=22000\n",
            "2026-02-19 10:15:32 [debug    ] train_step                     loss=-3.209737 lr=8.95e-05 step=22050\n",
            "2026-02-19 10:15:33 [debug    ] train_step                     loss=-3.114077 lr=8.94e-05 step=22100\n",
            "2026-02-19 10:15:33 [info     ] epoch_complete                 epoch=22 lr=8.94e-05 train_loss=-3.111477 val_loss=-3.252089\n",
            "2026-02-19 10:15:34 [debug    ] train_step                     loss=-3.286944 lr=8.94e-05 step=22150\n",
            "2026-02-19 10:15:34 [debug    ] train_step                     loss=-3.063632 lr=8.93e-05 step=22200\n",
            "2026-02-19 10:15:35 [debug    ] train_step                     loss=-3.235654 lr=8.93e-05 step=22250\n",
            "2026-02-19 10:15:36 [debug    ] train_step                     loss=-3.178092 lr=8.92e-05 step=22300\n",
            "2026-02-19 10:15:36 [debug    ] train_step                     loss=-3.266113 lr=8.92e-05 step=22350\n",
            "2026-02-19 10:15:37 [debug    ] train_step                     loss=-3.159264 lr=8.91e-05 step=22400\n",
            "2026-02-19 10:15:37 [debug    ] train_step                     loss=-2.929168 lr=8.91e-05 step=22450\n",
            "2026-02-19 10:15:38 [debug    ] train_step                     loss=-3.101190 lr=8.90e-05 step=22500\n",
            "2026-02-19 10:15:38 [debug    ] train_step                     loss=-2.932929 lr=8.90e-05 step=22550\n",
            "2026-02-19 10:15:39 [debug    ] train_step                     loss=-3.185052 lr=8.89e-05 step=22600\n",
            "2026-02-19 10:15:39 [debug    ] train_step                     loss=-3.005063 lr=8.89e-05 step=22650\n",
            "2026-02-19 10:15:40 [debug    ] train_step                     loss=-3.297545 lr=8.88e-05 step=22700\n",
            "2026-02-19 10:15:40 [debug    ] train_step                     loss=-3.248912 lr=8.88e-05 step=22750\n",
            "2026-02-19 10:15:41 [debug    ] train_step                     loss=-3.172168 lr=8.87e-05 step=22800\n",
            "2026-02-19 10:15:41 [debug    ] train_step                     loss=-2.992020 lr=8.87e-05 step=22850\n",
            "2026-02-19 10:15:42 [debug    ] train_step                     loss=-3.234752 lr=8.86e-05 step=22900\n",
            "2026-02-19 10:15:42 [debug    ] train_step                     loss=-3.235215 lr=8.86e-05 step=22950\n",
            "2026-02-19 10:15:43 [debug    ] train_step                     loss=-3.183253 lr=8.85e-05 step=23000\n",
            "2026-02-19 10:15:43 [debug    ] train_step                     loss=-2.974643 lr=8.85e-05 step=23050\n",
            "2026-02-19 10:15:44 [debug    ] train_step                     loss=-3.041877 lr=8.84e-05 step=23100\n",
            "2026-02-19 10:15:45 [info     ] epoch_complete                 epoch=23 lr=8.84e-05 train_loss=-3.113533 val_loss=-3.296087\n",
            "2026-02-19 10:15:45 [debug    ] train_step                     loss=-3.046199 lr=8.84e-05 step=23150\n",
            "2026-02-19 10:15:46 [debug    ] train_step                     loss=-3.199789 lr=8.83e-05 step=23200\n",
            "2026-02-19 10:15:46 [debug    ] train_step                     loss=-2.931015 lr=8.83e-05 step=23250\n",
            "2026-02-19 10:15:47 [debug    ] train_step                     loss=-3.165648 lr=8.82e-05 step=23300\n",
            "2026-02-19 10:15:47 [debug    ] train_step                     loss=-3.003569 lr=8.82e-05 step=23350\n",
            "2026-02-19 10:15:48 [debug    ] train_step                     loss=-3.054407 lr=8.81e-05 step=23400\n",
            "2026-02-19 10:15:48 [debug    ] train_step                     loss=-3.130322 lr=8.81e-05 step=23450\n",
            "2026-02-19 10:15:49 [debug    ] train_step                     loss=-3.126760 lr=8.80e-05 step=23500\n",
            "2026-02-19 10:15:49 [debug    ] train_step                     loss=-3.100946 lr=8.80e-05 step=23550\n",
            "2026-02-19 10:15:50 [debug    ] train_step                     loss=-3.011288 lr=8.79e-05 step=23600\n",
            "2026-02-19 10:15:50 [debug    ] train_step                     loss=-3.210030 lr=8.79e-05 step=23650\n",
            "2026-02-19 10:15:51 [debug    ] train_step                     loss=-3.310207 lr=8.78e-05 step=23700\n",
            "2026-02-19 10:15:51 [debug    ] train_step                     loss=-2.959428 lr=8.78e-05 step=23750\n",
            "2026-02-19 10:15:52 [debug    ] train_step                     loss=-3.266436 lr=8.77e-05 step=23800\n",
            "2026-02-19 10:15:52 [debug    ] train_step                     loss=-3.220960 lr=8.77e-05 step=23850\n",
            "2026-02-19 10:15:53 [debug    ] train_step                     loss=-2.944440 lr=8.76e-05 step=23900\n",
            "2026-02-19 10:15:53 [debug    ] train_step                     loss=-3.167418 lr=8.76e-05 step=23950\n",
            "2026-02-19 10:15:54 [debug    ] train_step                     loss=-3.070728 lr=8.75e-05 step=24000\n",
            "2026-02-19 10:15:54 [debug    ] train_step                     loss=-3.099238 lr=8.75e-05 step=24050\n",
            "2026-02-19 10:15:55 [debug    ] train_step                     loss=-3.082618 lr=8.74e-05 step=24100\n",
            "2026-02-19 10:15:56 [info     ] epoch_complete                 epoch=24 lr=8.74e-05 train_loss=-3.118315 val_loss=-3.279352\n",
            "2026-02-19 10:15:56 [debug    ] train_step                     loss=-3.138134 lr=8.74e-05 step=24150\n",
            "2026-02-19 10:15:57 [debug    ] train_step                     loss=-3.298087 lr=8.73e-05 step=24200\n",
            "2026-02-19 10:15:57 [debug    ] train_step                     loss=-3.012163 lr=8.73e-05 step=24250\n",
            "2026-02-19 10:15:58 [debug    ] train_step                     loss=-3.274411 lr=8.72e-05 step=24300\n",
            "2026-02-19 10:15:58 [debug    ] train_step                     loss=-2.992665 lr=8.71e-05 step=24350\n",
            "2026-02-19 10:15:59 [debug    ] train_step                     loss=-3.262226 lr=8.71e-05 step=24400\n",
            "2026-02-19 10:15:59 [debug    ] train_step                     loss=-3.209594 lr=8.70e-05 step=24450\n",
            "2026-02-19 10:16:00 [debug    ] train_step                     loss=-3.323851 lr=8.70e-05 step=24500\n",
            "2026-02-19 10:16:00 [debug    ] train_step                     loss=-3.018476 lr=8.69e-05 step=24550\n",
            "2026-02-19 10:16:01 [debug    ] train_step                     loss=-3.246692 lr=8.69e-05 step=24600\n",
            "2026-02-19 10:16:01 [debug    ] train_step                     loss=-2.991108 lr=8.68e-05 step=24650\n",
            "2026-02-19 10:16:02 [debug    ] train_step                     loss=-3.111695 lr=8.68e-05 step=24700\n",
            "2026-02-19 10:16:02 [debug    ] train_step                     loss=-3.101354 lr=8.67e-05 step=24750\n",
            "2026-02-19 10:16:03 [debug    ] train_step                     loss=-3.066776 lr=8.67e-05 step=24800\n",
            "2026-02-19 10:16:04 [debug    ] train_step                     loss=-3.206079 lr=8.66e-05 step=24850\n",
            "2026-02-19 10:16:04 [debug    ] train_step                     loss=-3.054008 lr=8.66e-05 step=24900\n",
            "2026-02-19 10:16:05 [debug    ] train_step                     loss=-3.216104 lr=8.65e-05 step=24950\n",
            "2026-02-19 10:16:05 [debug    ] train_step                     loss=-3.116203 lr=8.65e-05 step=25000\n",
            "2026-02-19 10:16:06 [debug    ] train_step                     loss=-2.885842 lr=8.64e-05 step=25050\n",
            "2026-02-19 10:16:06 [debug    ] train_step                     loss=-2.960849 lr=8.63e-05 step=25100\n",
            "2026-02-19 10:16:07 [info     ] epoch_complete                 epoch=25 lr=8.63e-05 train_loss=-3.118550 val_loss=-3.163911\n",
            "2026-02-19 10:16:07 [debug    ] train_step                     loss=-3.254628 lr=8.63e-05 step=25150\n",
            "2026-02-19 10:16:08 [debug    ] train_step                     loss=-3.162692 lr=8.62e-05 step=25200\n",
            "2026-02-19 10:16:08 [debug    ] train_step                     loss=-2.919485 lr=8.62e-05 step=25250\n",
            "2026-02-19 10:16:09 [debug    ] train_step                     loss=-3.036958 lr=8.61e-05 step=25300\n",
            "2026-02-19 10:16:09 [debug    ] train_step                     loss=-3.264093 lr=8.61e-05 step=25350\n",
            "2026-02-19 10:16:10 [debug    ] train_step                     loss=-3.018381 lr=8.60e-05 step=25400\n",
            "2026-02-19 10:16:10 [debug    ] train_step                     loss=-3.038927 lr=8.60e-05 step=25450\n",
            "2026-02-19 10:16:11 [debug    ] train_step                     loss=-3.117338 lr=8.59e-05 step=25500\n",
            "2026-02-19 10:16:12 [debug    ] train_step                     loss=-2.803694 lr=8.59e-05 step=25550\n",
            "2026-02-19 10:16:12 [debug    ] train_step                     loss=-3.120621 lr=8.58e-05 step=25600\n",
            "2026-02-19 10:16:13 [debug    ] train_step                     loss=-3.068613 lr=8.57e-05 step=25650\n",
            "2026-02-19 10:16:13 [debug    ] train_step                     loss=-2.989256 lr=8.57e-05 step=25700\n",
            "2026-02-19 10:16:14 [debug    ] train_step                     loss=-3.202756 lr=8.56e-05 step=25750\n",
            "2026-02-19 10:16:14 [debug    ] train_step                     loss=-3.149092 lr=8.56e-05 step=25800\n",
            "2026-02-19 10:16:15 [debug    ] train_step                     loss=-3.170744 lr=8.55e-05 step=25850\n",
            "2026-02-19 10:16:15 [debug    ] train_step                     loss=-3.154686 lr=8.55e-05 step=25900\n",
            "2026-02-19 10:16:16 [debug    ] train_step                     loss=-3.211770 lr=8.54e-05 step=25950\n",
            "2026-02-19 10:16:16 [debug    ] train_step                     loss=-3.072836 lr=8.54e-05 step=26000\n",
            "2026-02-19 10:16:17 [debug    ] train_step                     loss=-3.176816 lr=8.53e-05 step=26050\n",
            "2026-02-19 10:16:17 [debug    ] train_step                     loss=-3.160936 lr=8.53e-05 step=26100\n",
            "2026-02-19 10:16:18 [info     ] epoch_complete                 epoch=26 lr=8.52e-05 train_loss=-3.120566 val_loss=-3.242856\n",
            "2026-02-19 10:16:18 [debug    ] train_step                     loss=-3.166779 lr=8.52e-05 step=26150\n",
            "2026-02-19 10:16:19 [debug    ] train_step                     loss=-3.033772 lr=8.51e-05 step=26200\n",
            "2026-02-19 10:16:19 [debug    ] train_step                     loss=-3.133187 lr=8.51e-05 step=26250\n",
            "2026-02-19 10:16:20 [debug    ] train_step                     loss=-3.085859 lr=8.50e-05 step=26300\n",
            "2026-02-19 10:16:20 [debug    ] train_step                     loss=-3.037539 lr=8.50e-05 step=26350\n",
            "2026-02-19 10:16:21 [debug    ] train_step                     loss=-3.163679 lr=8.49e-05 step=26400\n",
            "2026-02-19 10:16:21 [debug    ] train_step                     loss=-3.019252 lr=8.49e-05 step=26450\n",
            "2026-02-19 10:16:22 [debug    ] train_step                     loss=-3.002010 lr=8.48e-05 step=26500\n",
            "2026-02-19 10:16:23 [debug    ] train_step                     loss=-3.254771 lr=8.47e-05 step=26550\n",
            "2026-02-19 10:16:23 [debug    ] train_step                     loss=-3.085788 lr=8.47e-05 step=26600\n",
            "2026-02-19 10:16:24 [debug    ] train_step                     loss=-3.220804 lr=8.46e-05 step=26650\n",
            "2026-02-19 10:16:24 [debug    ] train_step                     loss=-3.179893 lr=8.46e-05 step=26700\n",
            "2026-02-19 10:16:25 [debug    ] train_step                     loss=-3.213044 lr=8.45e-05 step=26750\n",
            "2026-02-19 10:16:25 [debug    ] train_step                     loss=-3.195268 lr=8.45e-05 step=26800\n",
            "2026-02-19 10:16:26 [debug    ] train_step                     loss=-2.743963 lr=8.44e-05 step=26850\n",
            "2026-02-19 10:16:26 [debug    ] train_step                     loss=-3.118328 lr=8.44e-05 step=26900\n",
            "2026-02-19 10:16:27 [debug    ] train_step                     loss=-3.167711 lr=8.43e-05 step=26950\n",
            "2026-02-19 10:16:27 [debug    ] train_step                     loss=-2.902658 lr=8.42e-05 step=27000\n",
            "2026-02-19 10:16:28 [debug    ] train_step                     loss=-3.063758 lr=8.42e-05 step=27050\n",
            "2026-02-19 10:16:28 [debug    ] train_step                     loss=-3.284595 lr=8.41e-05 step=27100\n",
            "2026-02-19 10:16:29 [info     ] epoch_complete                 epoch=27 lr=8.41e-05 train_loss=-3.124890 val_loss=-3.265012\n",
            "2026-02-19 10:16:30 [debug    ] train_step                     loss=-2.644907 lr=8.41e-05 step=27150\n",
            "2026-02-19 10:16:30 [debug    ] train_step                     loss=-3.181389 lr=8.40e-05 step=27200\n",
            "2026-02-19 10:16:31 [debug    ] train_step                     loss=-3.285065 lr=8.39e-05 step=27250\n",
            "2026-02-19 10:16:31 [debug    ] train_step                     loss=-3.198142 lr=8.39e-05 step=27300\n",
            "2026-02-19 10:16:32 [debug    ] train_step                     loss=-3.155325 lr=8.38e-05 step=27350\n",
            "2026-02-19 10:16:32 [debug    ] train_step                     loss=-3.236319 lr=8.38e-05 step=27400\n",
            "2026-02-19 10:16:33 [debug    ] train_step                     loss=-2.935017 lr=8.37e-05 step=27450\n",
            "2026-02-19 10:16:33 [debug    ] train_step                     loss=-3.138186 lr=8.37e-05 step=27500\n",
            "2026-02-19 10:16:34 [debug    ] train_step                     loss=-3.086736 lr=8.36e-05 step=27550\n",
            "2026-02-19 10:16:34 [debug    ] train_step                     loss=-3.243847 lr=8.35e-05 step=27600\n",
            "2026-02-19 10:16:35 [debug    ] train_step                     loss=-3.100344 lr=8.35e-05 step=27650\n",
            "2026-02-19 10:16:35 [debug    ] train_step                     loss=-2.860316 lr=8.34e-05 step=27700\n",
            "2026-02-19 10:16:36 [debug    ] train_step                     loss=-2.992308 lr=8.34e-05 step=27750\n",
            "2026-02-19 10:16:36 [debug    ] train_step                     loss=-3.154259 lr=8.33e-05 step=27800\n",
            "2026-02-19 10:16:37 [debug    ] train_step                     loss=-3.183733 lr=8.33e-05 step=27850\n",
            "2026-02-19 10:16:37 [debug    ] train_step                     loss=-2.995005 lr=8.32e-05 step=27900\n",
            "2026-02-19 10:16:38 [debug    ] train_step                     loss=-3.119344 lr=8.31e-05 step=27950\n",
            "2026-02-19 10:16:38 [debug    ] train_step                     loss=-3.213737 lr=8.31e-05 step=28000\n",
            "2026-02-19 10:16:39 [debug    ] train_step                     loss=-3.106939 lr=8.30e-05 step=28050\n",
            "2026-02-19 10:16:39 [debug    ] train_step                     loss=-3.211551 lr=8.30e-05 step=28100\n",
            "2026-02-19 10:16:40 [info     ] epoch_complete                 epoch=28 lr=8.29e-05 train_loss=-3.126547 val_loss=-3.262492\n",
            "2026-02-19 10:16:41 [debug    ] train_step                     loss=-3.136773 lr=8.29e-05 step=28150\n",
            "2026-02-19 10:16:41 [debug    ] train_step                     loss=-3.133157 lr=8.28e-05 step=28200\n",
            "2026-02-19 10:16:42 [debug    ] train_step                     loss=-3.071995 lr=8.28e-05 step=28250\n",
            "2026-02-19 10:16:42 [debug    ] train_step                     loss=-3.129118 lr=8.27e-05 step=28300\n",
            "2026-02-19 10:16:43 [debug    ] train_step                     loss=-3.168463 lr=8.27e-05 step=28350\n",
            "2026-02-19 10:16:43 [debug    ] train_step                     loss=-3.118265 lr=8.26e-05 step=28400\n",
            "2026-02-19 10:16:44 [debug    ] train_step                     loss=-3.178957 lr=8.25e-05 step=28450\n",
            "2026-02-19 10:16:44 [debug    ] train_step                     loss=-3.164423 lr=8.25e-05 step=28500\n",
            "2026-02-19 10:16:45 [debug    ] train_step                     loss=-3.135050 lr=8.24e-05 step=28550\n",
            "2026-02-19 10:16:45 [debug    ] train_step                     loss=-3.039121 lr=8.24e-05 step=28600\n",
            "2026-02-19 10:16:46 [debug    ] train_step                     loss=-3.083603 lr=8.23e-05 step=28650\n",
            "2026-02-19 10:16:46 [debug    ] train_step                     loss=-3.249248 lr=8.22e-05 step=28700\n",
            "2026-02-19 10:16:47 [debug    ] train_step                     loss=-2.739782 lr=8.22e-05 step=28750\n",
            "2026-02-19 10:16:47 [debug    ] train_step                     loss=-2.823865 lr=8.21e-05 step=28800\n",
            "2026-02-19 10:16:48 [debug    ] train_step                     loss=-3.279061 lr=8.21e-05 step=28850\n",
            "2026-02-19 10:16:48 [debug    ] train_step                     loss=-3.106578 lr=8.20e-05 step=28900\n",
            "2026-02-19 10:16:49 [debug    ] train_step                     loss=-3.078248 lr=8.19e-05 step=28950\n",
            "2026-02-19 10:16:49 [debug    ] train_step                     loss=-3.142106 lr=8.19e-05 step=29000\n",
            "2026-02-19 10:16:50 [debug    ] train_step                     loss=-3.069341 lr=8.18e-05 step=29050\n",
            "2026-02-19 10:16:50 [debug    ] train_step                     loss=-3.179158 lr=8.18e-05 step=29100\n",
            "2026-02-19 10:16:51 [info     ] epoch_complete                 epoch=29 lr=8.17e-05 train_loss=-3.131738 val_loss=-3.287449\n",
            "2026-02-19 10:16:52 [debug    ] train_step                     loss=-3.084784 lr=8.17e-05 step=29150\n",
            "2026-02-19 10:16:52 [debug    ] train_step                     loss=-2.857651 lr=8.16e-05 step=29200\n",
            "2026-02-19 10:16:53 [debug    ] train_step                     loss=-2.965695 lr=8.16e-05 step=29250\n",
            "2026-02-19 10:16:53 [debug    ] train_step                     loss=-3.154598 lr=8.15e-05 step=29300\n",
            "2026-02-19 10:16:54 [debug    ] train_step                     loss=-3.072754 lr=8.15e-05 step=29350\n",
            "2026-02-19 10:16:54 [debug    ] train_step                     loss=-3.192599 lr=8.14e-05 step=29400\n",
            "2026-02-19 10:16:55 [debug    ] train_step                     loss=-3.208325 lr=8.13e-05 step=29450\n",
            "2026-02-19 10:16:55 [debug    ] train_step                     loss=-3.126366 lr=8.13e-05 step=29500\n",
            "2026-02-19 10:16:56 [debug    ] train_step                     loss=-3.193626 lr=8.12e-05 step=29550\n",
            "2026-02-19 10:16:56 [debug    ] train_step                     loss=-2.876281 lr=8.12e-05 step=29600\n",
            "2026-02-19 10:16:57 [debug    ] train_step                     loss=-2.999205 lr=8.11e-05 step=29650\n",
            "2026-02-19 10:16:57 [debug    ] train_step                     loss=-3.180888 lr=8.10e-05 step=29700\n",
            "2026-02-19 10:16:58 [debug    ] train_step                     loss=-2.992529 lr=8.10e-05 step=29750\n",
            "2026-02-19 10:16:58 [debug    ] train_step                     loss=-3.204379 lr=8.09e-05 step=29800\n",
            "2026-02-19 10:16:59 [debug    ] train_step                     loss=-3.168505 lr=8.08e-05 step=29850\n",
            "2026-02-19 10:16:59 [debug    ] train_step                     loss=-2.996666 lr=8.08e-05 step=29900\n",
            "2026-02-19 10:17:00 [debug    ] train_step                     loss=-3.179314 lr=8.07e-05 step=29950\n",
            "2026-02-19 10:17:01 [debug    ] train_step                     loss=-3.253659 lr=8.07e-05 step=30000\n",
            "2026-02-19 10:17:01 [debug    ] train_step                     loss=-3.236647 lr=8.06e-05 step=30050\n",
            "2026-02-19 10:17:02 [debug    ] train_step                     loss=-3.225383 lr=8.05e-05 step=30100\n",
            "2026-02-19 10:17:02 [debug    ] train_step                     loss=-3.057500 lr=8.05e-05 step=30150\n",
            "2026-02-19 10:17:03 [info     ] epoch_complete                 epoch=30 lr=8.05e-05 train_loss=-3.134691 val_loss=-3.280348\n",
            "2026-02-19 10:17:03 [debug    ] train_step                     loss=-3.163417 lr=8.04e-05 step=30200\n",
            "2026-02-19 10:17:04 [debug    ] train_step                     loss=-3.198395 lr=8.03e-05 step=30250\n",
            "2026-02-19 10:17:04 [debug    ] train_step                     loss=-3.254697 lr=8.03e-05 step=30300\n",
            "2026-02-19 10:17:05 [debug    ] train_step                     loss=-3.197774 lr=8.02e-05 step=30350\n",
            "2026-02-19 10:17:05 [debug    ] train_step                     loss=-3.155350 lr=8.02e-05 step=30400\n",
            "2026-02-19 10:17:06 [debug    ] train_step                     loss=-3.108139 lr=8.01e-05 step=30450\n",
            "2026-02-19 10:17:07 [debug    ] train_step                     loss=-3.137812 lr=8.00e-05 step=30500\n",
            "2026-02-19 10:17:07 [debug    ] train_step                     loss=-3.080642 lr=8.00e-05 step=30550\n",
            "2026-02-19 10:17:08 [debug    ] train_step                     loss=-2.959179 lr=7.99e-05 step=30600\n",
            "2026-02-19 10:17:08 [debug    ] train_step                     loss=-3.039529 lr=7.98e-05 step=30650\n",
            "2026-02-19 10:17:09 [debug    ] train_step                     loss=-2.956949 lr=7.98e-05 step=30700\n",
            "2026-02-19 10:17:09 [debug    ] train_step                     loss=-3.261611 lr=7.97e-05 step=30750\n",
            "2026-02-19 10:17:10 [debug    ] train_step                     loss=-3.140119 lr=7.97e-05 step=30800\n",
            "2026-02-19 10:17:11 [debug    ] train_step                     loss=-3.073108 lr=7.96e-05 step=30850\n",
            "2026-02-19 10:17:11 [debug    ] train_step                     loss=-3.071471 lr=7.95e-05 step=30900\n",
            "2026-02-19 10:17:12 [debug    ] train_step                     loss=-3.229244 lr=7.95e-05 step=30950\n",
            "2026-02-19 10:17:12 [debug    ] train_step                     loss=-3.123205 lr=7.94e-05 step=31000\n",
            "2026-02-19 10:17:13 [debug    ] train_step                     loss=-3.170430 lr=7.93e-05 step=31050\n",
            "2026-02-19 10:17:13 [debug    ] train_step                     loss=-3.255446 lr=7.93e-05 step=31100\n",
            "2026-02-19 10:17:14 [debug    ] train_step                     loss=-2.631343 lr=7.92e-05 step=31150\n",
            "2026-02-19 10:17:14 [info     ] epoch_complete                 epoch=31 lr=7.92e-05 train_loss=-3.133305 val_loss=-3.284760\n",
            "2026-02-19 10:17:15 [debug    ] train_step                     loss=-3.192706 lr=7.92e-05 step=31200\n",
            "2026-02-19 10:17:15 [debug    ] train_step                     loss=-3.249330 lr=7.91e-05 step=31250\n",
            "2026-02-19 10:17:16 [debug    ] train_step                     loss=-3.173792 lr=7.90e-05 step=31300\n",
            "2026-02-19 10:17:17 [debug    ] train_step                     loss=-3.178747 lr=7.90e-05 step=31350\n",
            "2026-02-19 10:17:17 [debug    ] train_step                     loss=-3.121305 lr=7.89e-05 step=31400\n",
            "2026-02-19 10:17:18 [debug    ] train_step                     loss=-3.239711 lr=7.88e-05 step=31450\n",
            "2026-02-19 10:17:18 [debug    ] train_step                     loss=-3.252698 lr=7.88e-05 step=31500\n",
            "2026-02-19 10:17:19 [debug    ] train_step                     loss=-3.257341 lr=7.87e-05 step=31550\n",
            "2026-02-19 10:17:19 [debug    ] train_step                     loss=-2.939588 lr=7.86e-05 step=31600\n",
            "2026-02-19 10:17:20 [debug    ] train_step                     loss=-3.117288 lr=7.86e-05 step=31650\n",
            "2026-02-19 10:17:20 [debug    ] train_step                     loss=-3.137788 lr=7.85e-05 step=31700\n",
            "2026-02-19 10:17:21 [debug    ] train_step                     loss=-3.265820 lr=7.84e-05 step=31750\n",
            "2026-02-19 10:17:21 [debug    ] train_step                     loss=-3.213807 lr=7.84e-05 step=31800\n",
            "2026-02-19 10:17:22 [debug    ] train_step                     loss=-3.138854 lr=7.83e-05 step=31850\n",
            "2026-02-19 10:17:22 [debug    ] train_step                     loss=-3.275909 lr=7.83e-05 step=31900\n",
            "2026-02-19 10:17:23 [debug    ] train_step                     loss=-3.067288 lr=7.82e-05 step=31950\n",
            "2026-02-19 10:17:23 [debug    ] train_step                     loss=-3.106827 lr=7.81e-05 step=32000\n",
            "2026-02-19 10:17:24 [debug    ] train_step                     loss=-3.058995 lr=7.81e-05 step=32050\n",
            "2026-02-19 10:17:24 [debug    ] train_step                     loss=-3.181791 lr=7.80e-05 step=32100\n",
            "2026-02-19 10:17:25 [debug    ] train_step                     loss=-3.182816 lr=7.79e-05 step=32150\n",
            "2026-02-19 10:17:26 [info     ] epoch_complete                 epoch=32 lr=7.79e-05 train_loss=-3.138496 val_loss=-3.288113\n",
            "2026-02-19 10:17:26 [debug    ] train_step                     loss=-3.174629 lr=7.79e-05 step=32200\n",
            "2026-02-19 10:17:27 [debug    ] train_step                     loss=-3.236524 lr=7.78e-05 step=32250\n",
            "2026-02-19 10:17:27 [debug    ] train_step                     loss=-3.247402 lr=7.77e-05 step=32300\n",
            "2026-02-19 10:17:28 [debug    ] train_step                     loss=-3.055391 lr=7.77e-05 step=32350\n",
            "2026-02-19 10:17:28 [debug    ] train_step                     loss=-3.263151 lr=7.76e-05 step=32400\n",
            "2026-02-19 10:17:29 [debug    ] train_step                     loss=-3.279436 lr=7.75e-05 step=32450\n",
            "2026-02-19 10:17:29 [debug    ] train_step                     loss=-3.277852 lr=7.75e-05 step=32500\n",
            "2026-02-19 10:17:30 [debug    ] train_step                     loss=-3.138775 lr=7.74e-05 step=32550\n",
            "2026-02-19 10:17:30 [debug    ] train_step                     loss=-3.169670 lr=7.73e-05 step=32600\n",
            "2026-02-19 10:17:31 [debug    ] train_step                     loss=-3.147642 lr=7.73e-05 step=32650\n",
            "2026-02-19 10:17:31 [debug    ] train_step                     loss=-3.151814 lr=7.72e-05 step=32700\n",
            "2026-02-19 10:17:32 [debug    ] train_step                     loss=-3.000155 lr=7.71e-05 step=32750\n",
            "2026-02-19 10:17:32 [debug    ] train_step                     loss=-3.171035 lr=7.71e-05 step=32800\n",
            "2026-02-19 10:17:33 [debug    ] train_step                     loss=-3.168489 lr=7.70e-05 step=32850\n",
            "2026-02-19 10:17:34 [debug    ] train_step                     loss=-3.256493 lr=7.69e-05 step=32900\n",
            "2026-02-19 10:17:34 [debug    ] train_step                     loss=-3.175627 lr=7.69e-05 step=32950\n",
            "2026-02-19 10:17:35 [debug    ] train_step                     loss=-2.903524 lr=7.68e-05 step=33000\n",
            "2026-02-19 10:17:35 [debug    ] train_step                     loss=-3.176812 lr=7.67e-05 step=33050\n",
            "2026-02-19 10:17:36 [debug    ] train_step                     loss=-2.897073 lr=7.67e-05 step=33100\n",
            "2026-02-19 10:17:36 [debug    ] train_step                     loss=-3.098579 lr=7.66e-05 step=33150\n",
            "2026-02-19 10:17:37 [info     ] epoch_complete                 epoch=33 lr=7.66e-05 train_loss=-3.136875 val_loss=-3.258707\n",
            "2026-02-19 10:17:37 [info     ] early_stopping                 best_score=-3.3054871033813993 patience=15\n",
            "2026-02-19 10:17:37 [info     ] early_stopping_triggered       epoch=33\n",
            "2026-02-19 10:17:37 [info     ] training_complete              epochs_run=33\n",
            "\n",
            "Training done in 6.2 min\n",
            "Final train loss: -3.136875\n",
            "Final val loss: -3.258707\n",
            "Best val loss: -3.305487\n",
            "Transformer model saved to Drive!\n"
          ]
        }
      ],
      "source": [
        "# === TRANSFORMER TRAINING (H100 optimized) ===\n",
        "import time\n",
        "from quant_lab.models.transformer.model import TransformerForecaster, TransformerConfig, MultiTaskLoss\n",
        "from quant_lab.training.trainer import Trainer, TrainerConfig\n",
        "\n",
        "set_global_seed(42)\n",
        "device = get_device()\n",
        "\n",
        "# Proper train/val split\n",
        "split = TemporalSplit(train_end='2021-12-31', val_end='2023-06-30')\n",
        "dm = QuantDataModule(\n",
        "    feature_df, feature_cols, split,\n",
        "    DataModuleConfig(sequence_length=63, target_col='log_return_1d', batch_size=128, num_workers=2),\n",
        ")\n",
        "dm.setup()\n",
        "train_loader = dm.train_dataloader()\n",
        "val_loader = dm.val_dataloader()\n",
        "\n",
        "# H100-optimized model\n",
        "model_cfg = TransformerConfig(\n",
        "    num_features=dm.num_features,\n",
        "    d_model=256,\n",
        "    nhead=8,\n",
        "    num_encoder_layers=6,\n",
        "    dim_feedforward=1024,\n",
        "    dropout=0.1,\n",
        "    activation='gelu',\n",
        "    distribution_type='gaussian',\n",
        "    direction_num_classes=3,\n",
        "    direction_threshold=0.005,\n",
        "    volatility_enabled=True,\n",
        "    distribution_weight=1.0,\n",
        "    direction_weight=0.3,\n",
        "    volatility_weight=0.3,\n",
        ")\n",
        "model = TransformerForecaster(model_cfg)\n",
        "loss_fn = MultiTaskLoss(model_cfg)\n",
        "print(f\"Transformer parameters: {model.count_parameters():,}\")\n",
        "\n",
        "# Trainer\n",
        "trainer_config = TrainerConfig(\n",
        "    epochs=100,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=1e-5,\n",
        "    warmup_steps=1000,\n",
        "    max_grad_norm=1.0,\n",
        "    patience=15,\n",
        "    mixed_precision=True,\n",
        "    checkpoint_dir='outputs/models/transformer',\n",
        ")\n",
        "trainer = Trainer(model=model, loss_fn=loss_fn, config=trainer_config, device=device)\n",
        "\n",
        "start = time.time()\n",
        "history = trainer.fit(train_loader, val_loader)\n",
        "elapsed = time.time() - start\n",
        "\n",
        "print(f\"\\nTraining done in {elapsed/60:.1f} min\")\n",
        "print(f\"Final train loss: {history['train_loss'][-1]:.6f}\")\n",
        "if history['val_loss']:\n",
        "    print(f\"Final val loss: {history['val_loss'][-1]:.6f}\")\n",
        "    print(f\"Best val loss: {min(history['val_loss']):.6f}\")\n",
        "\n",
        "# Save to Drive\n",
        "model.save(Path('outputs/models/transformer/final_model.pt'))\n",
        "for f in Path('outputs/models/transformer').glob('*'):\n",
        "    shutil.copy(f, DRIVE_DIR / 'outputs/models/transformer' / f.name)\n",
        "print(\"Transformer model saved to Drive!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dhwcFwsBBGwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e4bd83-1dad-4ee3-c799-7ccac766ce6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NOTEBOOK A COMPLETE\n",
            "============================================================\n",
            "Pre-training loss: -3.136875\n",
            "Models saved to Google Drive: /content/drive/MyDrive/quant_lab/outputs/models\n",
            "\n",
            "Files on Drive:\n",
            "  outputs/models/pretrained/masked_encoder.pt: 23.8 MB\n",
            "  outputs/models/transformer/best.pt: 59.1 MB\n",
            "  outputs/models/transformer/final_model.pt: 21.1 MB\n",
            "  outputs/models/transformer/last.pt: 59.1 MB\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# === NOTEBOOK A SUMMARY ===\n",
        "print(\"=\" * 60)\n",
        "print(\"NOTEBOOK A COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Pre-training loss: {history['train_loss'][-1]:.6f}\")\n",
        "print(f\"Models saved to Google Drive: {DRIVE_DIR / 'outputs/models'}\")\n",
        "print(\"\\nFiles on Drive:\")\n",
        "for f in sorted((DRIVE_DIR / 'outputs/models').rglob('*')):\n",
        "    if f.is_file():\n",
        "        size_mb = f.stat().st_size / 1e6\n",
        "        print(f\"  {f.relative_to(DRIVE_DIR)}: {size_mb:.1f} MB\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "DRIVE_DIR = Path(\"/content/drive/MyDrive/quant_lab\")\n",
        "\n",
        "print(f\"Files in Google Drive directory: {DRIVE_DIR / 'outputs/models'}\")\n",
        "if (DRIVE_DIR / 'outputs/models').exists():\n",
        "    for f in sorted((DRIVE_DIR / 'outputs/models').rglob('*')):\n",
        "        if f.is_file():\n",
        "            size_mb = f.stat().st_size / 1e6\n",
        "            print(f\"  {f.relative_to(DRIVE_DIR)}: {size_mb:.1f} MB\")\n",
        "else:\n",
        "    print(\"No output models directory found in Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-tVrHYLaYCt",
        "outputId": "b3b49a98-9e9f-49bb-fed9-2bd53a7e1080"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Files in Google Drive directory: /content/drive/MyDrive/quant_lab/outputs/models\n",
            "  outputs/models/pretrained/masked_encoder.pt: 23.8 MB\n",
            "  outputs/models/transformer/best.pt: 59.1 MB\n",
            "  outputs/models/transformer/final_model.pt: 21.1 MB\n",
            "  outputs/models/transformer/last.pt: 59.1 MB\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "H100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}